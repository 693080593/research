{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feed Type Stratified Test Set Multi-split 041521 [4]_XgBoost.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1q4qENQEWL0KhKqsEMhkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/693080593/research/blob/master/Feed_Type_Stratified_Test_Set_Multi_split_041521_%5B4%5D_XgBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxqhn92z_ts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b705caea-1d0e-4896-cd8e-a1779edf0170"
      },
      "source": [
        "# Import libraries necessary for this project\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import supplementary visualizations code visuals.py\n",
        "import visuals as vs\n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Feed Type Effect on Biocrude 041521 Stratified Test.csv')\n",
        "Original_Oil_Yields = data['Bio-crude Oil Yield']\n",
        "Original_Features = data.drop('Bio-crude Oil Yield', axis = 1)\n",
        "\n",
        "data_figure = data.drop('Group', axis = 1)\n",
        "\n",
        "# Success\n",
        "print (\"Bio-crude dataset has {} data points with {} variables each.\".format(*data_figure.shape))\n",
        "data_figure.shape\n",
        "\n",
        "data_figure[:540:11]\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bio-crude dataset has 521 data points with 17 variables each.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algae</th>\n",
              "      <th>Manure</th>\n",
              "      <th>Lignocellulosic Biomass</th>\n",
              "      <th>Model Compounds</th>\n",
              "      <th>Food Waste</th>\n",
              "      <th>Sludge</th>\n",
              "      <th>Municipal Solid Waste</th>\n",
              "      <th>Bioethanol Residue</th>\n",
              "      <th>Plant Seed</th>\n",
              "      <th>Lipid</th>\n",
              "      <th>Protein</th>\n",
              "      <th>Cellulose</th>\n",
              "      <th>Hemicellulose</th>\n",
              "      <th>Carbohydrate</th>\n",
              "      <th>Lignin</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Bio-crude Oil Yield</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.400000</td>\n",
              "      <td>12.900000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.100000</td>\n",
              "      <td>74.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.50000</td>\n",
              "      <td>20.60000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.200000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>63.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>16.50000</td>\n",
              "      <td>16.50000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.700000</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>54.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>48.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.620000</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>26.470000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.220000</td>\n",
              "      <td>45.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>43.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.520000</td>\n",
              "      <td>43.810000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>42.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>40.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>33.500000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>42.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>39.615000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.737939</td>\n",
              "      <td>9.808050</td>\n",
              "      <td>82.85467</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.590000</td>\n",
              "      <td>38.260736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>83.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>58.600000</td>\n",
              "      <td>16.60000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>19.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>25.200000</td>\n",
              "      <td>6.50000</td>\n",
              "      <td>21.40000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>24.100000</td>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>15.70000</td>\n",
              "      <td>12.20000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>47.900000</td>\n",
              "      <td>12.40000</td>\n",
              "      <td>5.30000</td>\n",
              "      <td>17.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>33.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>22.100000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>36.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>32.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.962876</td>\n",
              "      <td>67.647373</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>25.409222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.980529</td>\n",
              "      <td>30.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>48.500000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>29.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.50000</td>\n",
              "      <td>37.20000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>38.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.800000</td>\n",
              "      <td>16.900000</td>\n",
              "      <td>18.20000</td>\n",
              "      <td>8.80000</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>34.600000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>26.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.400000</td>\n",
              "      <td>25.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>17.300000</td>\n",
              "      <td>37.10000</td>\n",
              "      <td>15.90000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>23.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>23.100000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>28.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.100000</td>\n",
              "      <td>19.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.681978</td>\n",
              "      <td>15.295100</td>\n",
              "      <td>14.86826</td>\n",
              "      <td>13.65888</td>\n",
              "      <td>13.445460</td>\n",
              "      <td>11.168980</td>\n",
              "      <td>28.860000</td>\n",
              "      <td>18.119358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>25.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.364000</td>\n",
              "      <td>23.780000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6.090000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>16.309600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.488000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>30.972000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.540000</td>\n",
              "      <td>15.524000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.20000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>13.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.768992</td>\n",
              "      <td>14.567650</td>\n",
              "      <td>19.27889</td>\n",
              "      <td>21.26257</td>\n",
              "      <td>1.599342</td>\n",
              "      <td>1.512556</td>\n",
              "      <td>38.010000</td>\n",
              "      <td>13.024099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>46.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.400000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>9.950000</td>\n",
              "      <td>9.04000</td>\n",
              "      <td>38.62000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.050000</td>\n",
              "      <td>43.430000</td>\n",
              "      <td>9.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>17.00000</td>\n",
              "      <td>1.30000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.60000</td>\n",
              "      <td>24.10000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.400000</td>\n",
              "      <td>4.610000</td>\n",
              "      <td>6.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.669720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Algae  Manure  ...        Ash  Bio-crude Oil Yield\n",
              "0      0.000000     0.0  ...   0.000000            98.500000\n",
              "11     0.000000     0.0  ...   3.100000            74.800000\n",
              "22     0.000000     0.0  ...   1.500000            63.200000\n",
              "33     0.000000     0.0  ...   0.000000            58.100000\n",
              "44   100.000000     0.0  ...   7.300000            54.300000\n",
              "55     0.000000     0.0  ...   0.000000            50.100000\n",
              "66   100.000000     0.0  ...   7.000000            48.000000\n",
              "77   100.000000     0.0  ...   6.220000            45.500000\n",
              "88   100.000000     0.0  ...   3.000000            43.700000\n",
              "99   100.000000     0.0  ...   4.500000            42.600000\n",
              "110  100.000000     0.0  ...   3.000000            40.900000\n",
              "121  100.000000     0.0  ...   5.000000            39.615000\n",
              "132    0.000000   100.0  ...   6.590000            38.260736\n",
              "143   83.333333     0.0  ...   0.000000            37.400000\n",
              "154   25.000000    75.0  ...  24.100000            36.000000\n",
              "165   50.000000     0.0  ...  20.000000            35.000000\n",
              "176    0.000000     0.0  ...   0.000000            34.100000\n",
              "187   75.000000     0.0  ...   4.200000            33.100000\n",
              "198  100.000000     0.0  ...  28.600000            32.400000\n",
              "209    0.000000     0.0  ...   0.000000            31.600000\n",
              "220  100.000000     0.0  ...  11.000000            31.000000\n",
              "231  100.000000     0.0  ...   5.980529            30.100000\n",
              "242  100.000000     0.0  ...   8.200000            29.200000\n",
              "253    0.000000     0.0  ...   0.000000            28.000000\n",
              "264   70.000000     0.0  ...   0.000000            27.100000\n",
              "275    0.000000     0.0  ...   4.500000            26.100000\n",
              "286  100.000000     0.0  ...  26.400000            25.600000\n",
              "297    0.000000     0.0  ...   0.000000            24.700000\n",
              "308   25.000000     0.0  ...   1.500000            23.700000\n",
              "319    0.000000     0.0  ...   0.000000            22.500000\n",
              "330    0.000000     0.0  ...   0.000000            21.400000\n",
              "341    0.000000     0.0  ...   0.000000            20.500000\n",
              "352  100.000000     0.0  ...  37.100000            19.700000\n",
              "363    0.000000     0.0  ...   0.000000            19.000000\n",
              "374    0.000000   100.0  ...  28.860000            18.119358\n",
              "385    0.000000     0.0  ...   0.000000            17.164200\n",
              "396  100.000000     0.0  ...  42.000000            16.309600\n",
              "407    0.000000     0.0  ...  10.540000            15.524000\n",
              "418  100.000000     0.0  ...  13.000000            14.700000\n",
              "429    0.000000     0.0  ...   0.500000            13.900000\n",
              "440    0.000000   100.0  ...  38.010000            13.024099\n",
              "451  100.000000     0.0  ...  25.400000            12.000000\n",
              "462    0.000000     0.0  ...   0.000000            10.960000\n",
              "473  100.000000     0.0  ...  43.430000             9.490000\n",
              "484   20.000000     0.0  ...   0.000000             7.600000\n",
              "495    0.000000     0.0  ...   4.610000             6.590000\n",
              "506    0.000000     0.0  ...   0.000000             5.900000\n",
              "517    0.000000     0.0  ...   0.000000             3.669720\n",
              "\n",
              "[48 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXrrKtldEvO1"
      },
      "source": [
        "# MinMaxScale\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#from pandas import DataFrame\n",
        "\n",
        "#data_MinMax = data2.drop(['Lipid','Protein','Cellulose','Hemicellulose','Carbohydrate','Lignin','Ash','Bio-crude Oil Yield','Group'], axis = 1)\n",
        "\n",
        "#scaler = MinMaxScaler()\n",
        "\n",
        "#print(scaler.fit(data_MinMax))\n",
        "\n",
        "#print(scaler.data_max_)\n",
        "#print(scaler.data_min_)\n",
        "\n",
        "#data_MinMax3 = scaler.transform(data_MinMax)\n",
        "\n",
        "#data_MinMax2 = pd.DataFrame(data = data_MinMax3*100,  columns =[\"Temperature\"])\n",
        "\n",
        "#print(data_MinMax2)\n",
        "\n",
        "#Original_Features = pd.concat([data2['Lipid'],data2['Protein'],data2['Cellulose'],data2['Hemicellulose'],data2['Carbohydrate'],data2['Lignin'],data2['Ash'],data_MinMax2, data2['Group']], axis=1)\n",
        "\n",
        "#data=pd.concat([Original_Features, data2['Bio-crude Oil Yield']], axis=1)\n",
        "\n",
        "#data_figure_new=data.drop('Group', axis = 1)\n",
        "\n",
        "#data[:517:11]\n",
        "\n",
        "#Original_Features[:511:11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhbMxqOIQfmS"
      },
      "source": [
        "import numpy as np\n",
        "# The mean relative error (MRE) is commonly used to measure the predictive accuracy of models.\n",
        "\n",
        "def performance_metric(y_true, y_predict):\n",
        "  \"\"\"Calculates and returns the performance score between \n",
        "        true and predicted values based on the metric chosen.\"\"\"\n",
        "  # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
        "\n",
        "  return np.mean(np.abs(y_true-y_predict))/np.mean(y_true)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO52jy5G0vdu"
      },
      "source": [
        "# No use.\n",
        "for j in range(0,201,1):\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=j)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "\n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "\n",
        "  cnt = 1\n",
        "  \n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  MRE_train_all=[]\n",
        "  MRE_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(1,50,1):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    model = XGBRegressor(silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    MRE_train = performance_metric(y_train, y_train_predict)\n",
        "    MRE_test = performance_metric(y_test, y_test_predict)\n",
        "\n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    MRE_train_all.append(MRE_train)\n",
        "    MRE_test_all.append(MRE_test)\n",
        "    \n",
        "  # Predict validation set\n",
        "  model.fit(Features_new, Oil_Yields)\n",
        "\n",
        "  y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  MRE_valid = performance_metric(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  print(\"R2 score of valid set\", r2_valid)\n",
        "  print(\"Max Values of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)\n",
        "  print(\"Difference Values of R2 of training and test sets\", np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  print(\"\")\n",
        "  #print(\"Mean value of MRE of training set\", np.mean(MRE_train_all))\n",
        "  #print(\"Mean value of MRE of test set\", np.mean(MRE_test_all))\n",
        "  #print(\"MRE of valid set:\", MRE_valid)\n",
        "  #print(\"Min Values of MRE of test set\", min(MRE_test_all))\n",
        "  #print(\"Standard deviation of MRE of test set\", np.std(MRE_test_all))\n",
        "  #print(\"Difference Values of MRE of training and test sets\", np.mean(MRE_train_all)-np.mean(MRE_test_all))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikEpsH7MUI68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e16f6b0-65f9-4b4d-ee92-2302156a2818"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "from math import sqrt\n",
        "from sklearn import metrics\n",
        "\n",
        "group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "# TODO: Shuffle and split the data into training and testing subsets\n",
        "Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "\n",
        "X_valid_new=X_valid.drop('Group', axis=1)\n",
        "\n",
        "Features_new=Features.drop('Group', axis=1)\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "MAE_train_all=[]\n",
        "MAE_test_all=[]\n",
        "y_train_rmse_all=[]\n",
        "y_test_rmse_all=[]\n",
        "r2_train_all=[]\n",
        "r2_test_all=[]\n",
        "MRE_train_all=[]\n",
        "MRE_test_all=[]\n",
        "y_test_list=[]\n",
        "y_pred_list=[]\n",
        "\n",
        "for i in range(5000,6000,10):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "  model = XGBRegressor(silent = True)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "    \n",
        "  y_train_predict = model.predict(X_train)\n",
        "  y_test_predict = model.predict(X_test)\n",
        "\n",
        "  MAE_train = metrics.mean_absolute_error(y_train, y_train_predict)\n",
        "  MAE_test = metrics.mean_absolute_error(y_test, y_test_predict)\n",
        "    \n",
        "  y_train_rmse = sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
        "  y_test_rmse = sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
        "    \n",
        "  r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "  r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "\n",
        "  MRE_train = performance_metric(y_train, y_train_predict)\n",
        "  MRE_test = performance_metric(y_test, y_test_predict)\n",
        "\n",
        "  cnt += 1\n",
        "  MAE_train_all.append(MAE_train)\n",
        "  MAE_test_all.append(MAE_test)\n",
        "  y_train_rmse_all.append(y_train_rmse)\n",
        "  y_test_rmse_all.append(y_test_rmse)\n",
        "  r2_train_all.append(r2_train)\n",
        "  r2_test_all.append(r2_test)\n",
        "  MRE_train_all.append(MRE_train)\n",
        "  MRE_test_all.append(MRE_test)\n",
        "\n",
        "  # For drawing plot\n",
        "  y_test_list.append(y_test.values)\n",
        "  y_pred_list.append(y_test_predict)  \n",
        "\n",
        "y_test_all=np.concatenate(y_test_list, axis=0)\n",
        "y_pred_all=np.concatenate(y_pred_list, axis=0)\n",
        "\n",
        "print(\"Mean value of MAE of training set\", np.mean(MAE_train_all))\n",
        "print(\"Standard deviation of MAE of training set\", np.std(MAE_train_all))\n",
        "print(\"Mean value of MAE of test set\", np.mean(MAE_test_all))\n",
        "print(\"Standard deviation of MAE of test set\", np.std(MAE_test_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of RMSE of training set\", np.mean(y_train_rmse_all))\n",
        "print(\"Standard deviation of RMSE of training set\", np.std(y_train_rmse_all))\n",
        "print(\"Mean value of RMSE of test set\", np.mean(y_test_rmse_all))\n",
        "print(\"Standard deviation of RMSE of test set\", np.std(y_test_rmse_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "print(\"Standard deviation of R2 of training set\", np.std(r2_train_all))\n",
        "print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "#print(\"Value of R2 of test set\", r2_test_all)\n",
        "print(\"\")\n",
        "print(\"Mean value of MRE of training set\", np.mean(MRE_train_all))\n",
        "print(\"Standard deviation of MRE of training set\", np.std(MRE_train_all))\n",
        "print(\"Mean value of MRE of test set\", np.mean(MRE_test_all))\n",
        "print(\"Standard deviation of MRE of test set\", np.std(MRE_test_all))\n",
        "\n",
        "print(\"\")\n",
        "# Predict validation set\n",
        "model.fit(Features_new, Oil_Yields)\n",
        "\n",
        "y_valid_predict = model.predict(X_valid_new)\n",
        "\n",
        "MAE_valid = metrics.mean_absolute_error(y_valid, y_valid_predict)\n",
        "y_valid_rmse = sqrt(metrics.mean_squared_error(y_valid, y_valid_predict))\n",
        "r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "MRE_valid = performance_metric(y_valid, y_valid_predict)\n",
        "\n",
        "print(\"MAE of valid set:\", MAE_valid)\n",
        "print(\"RMSE of valid set:\", y_valid_rmse)\n",
        "print(\"R2 score of valid set\", r2_valid)\n",
        "print(\"MRE of valid set:\", MRE_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean value of MAE of training set 4.4823662319439235\n",
            "Standard deviation of MAE of training set 0.12037030856300736\n",
            "Mean value of MAE of test set 7.056149737870171\n",
            "Standard deviation of MAE of test set 0.5477597999481904\n",
            "\n",
            "Mean value of RMSE of training set 5.8534766625891415\n",
            "Standard deviation of RMSE of training set 0.16144169154501975\n",
            "Mean value of RMSE of test set 9.320654458457819\n",
            "Standard deviation of RMSE of test set 0.8875678155955061\n",
            "\n",
            "Mean value of R2 of training set 0.887755326876592\n",
            "Standard deviation of R2 of training set 0.007651349737644005\n",
            "Mean value of R2 of test set 0.7028444696149474\n",
            "Standard deviation of R2 of test set 0.07623359453495142\n",
            "\n",
            "Mean value of MRE of training set 0.15076144163442778\n",
            "Standard deviation of MRE of training set 0.004639186456874886\n",
            "Mean value of MRE of test set 0.23902131775110874\n",
            "Standard deviation of MRE of test set 0.0237772879755071\n",
            "\n",
            "MAE of valid set: 6.3664905607992335\n",
            "RMSE of valid set: 8.362140312068908\n",
            "R2 score of valid set 0.7697647850906274\n",
            "MRE of valid set: 0.21469347404500272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "lDaa-0yLR8Tm",
        "outputId": "721aa3f8-2201-408a-e971-622ff79b051c"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_test_all, y_pred_all, 'bo')\n",
        "py.ylim(0, 100)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huXzQLHuaDz8"
      },
      "source": [
        "Parity={'Predict Data':y_pred_all,'Test Data':y_test_all}\n",
        "df = pd.DataFrame(Parity, columns= ['Predict Data', 'Test Data'])\n",
        "df.to_csv (r'/content/export_dataframe_XGBoost.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yDZJ9s3cRcnb",
        "outputId": "89d3a81c-9b94-4bea-b679-467b514ee2a4"
      },
      "source": [
        "from xgboost import plot_importance\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5z6KUkJkmRPz",
        "outputId": "fa3ffa3b-cdc8-40cd-db52-7e4767338f37"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_valid, y_valid_predict, 'bo')\n",
        "py.ylim(0, 100)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQoqEc6c6MLW"
      },
      "source": [
        "# n_estimators 参数的最佳取值(10, 200, 11)\n",
        "\n",
        "for j in range(10, 200, 10):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': j, 'gamma': 0, 'max_depth': 5, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JNuZUmg-UEt"
      },
      "source": [
        "# max_depth 参数的最佳取值(1, 20, 10)\n",
        "\n",
        "for j in range(1, 20, 1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': j, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU6KaKpAEUrg"
      },
      "source": [
        "# min_child_weight 参数的最佳取值(1, 10, 10)\n",
        "\n",
        "for j in range(0,11,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': j,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtEJ7EmrSVQT"
      },
      "source": [
        "# gamma 参数的最佳取值(0, 0.2, 11)\n",
        "\n",
        "for j in range(0,21,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': j/100, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/100)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSYJ-5AbTFvo"
      },
      "source": [
        "# subsample 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(5990,6010,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': j/10000, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10000)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_sddf_xXIKI"
      },
      "source": [
        "# colsample_bytree 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(0,11,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': j/10, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaH2veECXsK4"
      },
      "source": [
        "# reg_lambda 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(9680,9700,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': j/10000, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10000)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbm3tTrlZw7I"
      },
      "source": [
        "# reg_alpha 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(0,11,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': 0.9693, 'reg_alpha': j/10,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC2pDPB0bVXx"
      },
      "source": [
        "# eta 参数的最佳取值(-2, 0, 10)\n",
        "\n",
        "for j in range(0,10,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': j/100, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': 0.9693, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/100)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuE6JW9eb6pW"
      },
      "source": [
        "# seed 参数的最佳取值(0, 100, 1)\n",
        "\n",
        "for j in range(0,99,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': 0.9693, 'reg_alpha': 0,\n",
        "                'seed': j}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_Yields)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u9GRIXxn9eV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd49611-092d-416a-d2be-2fca221dc85a"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "from math import sqrt\n",
        "from sklearn import metrics\n",
        "\n",
        "group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "# TODO: Shuffle and split the data into training and testing subsets\n",
        "Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=62)\n",
        "\n",
        "X_valid_new=X_valid.drop('Group', axis=1)\n",
        "\n",
        "Features_new=Features.drop('Group', axis=1)\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "MAE_train_all=[]\n",
        "MAE_test_all=[]\n",
        "y_train_rmse_all=[]\n",
        "y_test_rmse_all=[]\n",
        "r2_train_all=[]\n",
        "r2_test_all=[]\n",
        "MRE_train_all=[]\n",
        "MRE_test_all=[]\n",
        "y_test_list=[]\n",
        "y_pred_list=[]\n",
        "\n",
        "for i in range(5000,6000,10):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "  other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': 0.9693, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "  model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "    \n",
        "  y_train_predict = model.predict(X_train)\n",
        "  y_test_predict = model.predict(X_test)\n",
        "\n",
        "  MAE_train = metrics.mean_absolute_error(y_train, y_train_predict)\n",
        "  MAE_test = metrics.mean_absolute_error(y_test, y_test_predict)\n",
        "    \n",
        "  y_train_rmse = sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
        "  y_test_rmse = sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
        "    \n",
        "  r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "  r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "\n",
        "  MRE_train = performance_metric(y_train, y_train_predict)\n",
        "  MRE_test = performance_metric(y_test, y_test_predict)\n",
        "\n",
        "  cnt += 1\n",
        "  MAE_train_all.append(MAE_train)\n",
        "  MAE_test_all.append(MAE_test)\n",
        "  y_train_rmse_all.append(y_train_rmse)\n",
        "  y_test_rmse_all.append(y_test_rmse)\n",
        "  r2_train_all.append(r2_train)\n",
        "  r2_test_all.append(r2_test)\n",
        "  MRE_train_all.append(MRE_train)\n",
        "  MRE_test_all.append(MRE_test)\n",
        "\n",
        "  # For drawing plot\n",
        "  y_test_list.append(y_test.values)\n",
        "  y_pred_list.append(y_test_predict)  \n",
        "\n",
        "y_test_all=np.concatenate(y_test_list, axis=0)\n",
        "y_pred_all=np.concatenate(y_pred_list, axis=0)\n",
        "\n",
        "print(\"Mean value of MAE of training set\", np.mean(MAE_train_all))\n",
        "print(\"Standard deviation of MAE of training set\", np.std(MAE_train_all))\n",
        "print(\"Mean value of MAE of test set\", np.mean(MAE_test_all))\n",
        "print(\"Standard deviation of MAE of test set\", np.std(MAE_test_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of RMSE of training set\", np.mean(y_train_rmse_all))\n",
        "print(\"Standard deviation of RMSE of training set\", np.std(y_train_rmse_all))\n",
        "print(\"Mean value of RMSE of test set\", np.mean(y_test_rmse_all))\n",
        "print(\"Standard deviation of RMSE of test set\", np.std(y_test_rmse_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "print(\"Standard deviation of R2 of training set\", np.std(r2_train_all))\n",
        "print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "#print(\"Value of R2 of test set\", r2_test_all)\n",
        "print(\"\")\n",
        "print(\"Mean value of MRE of training set\", np.mean(MRE_train_all))\n",
        "print(\"Standard deviation of MRE of training set\", np.std(MRE_train_all))\n",
        "print(\"Mean value of MRE of test set\", np.mean(MRE_test_all))\n",
        "print(\"Standard deviation of MRE of test set\", np.std(MRE_test_all))\n",
        "\n",
        "print(\"\")\n",
        "# Predict validation set\n",
        "model.fit(Features_new, Oil_Yields)\n",
        "\n",
        "y_valid_predict = model.predict(X_valid_new)\n",
        "\n",
        "MAE_valid = metrics.mean_absolute_error(y_valid, y_valid_predict)\n",
        "y_valid_rmse = sqrt(metrics.mean_squared_error(y_valid, y_valid_predict))\n",
        "r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "MRE_valid = performance_metric(y_valid, y_valid_predict)\n",
        "\n",
        "print(\"MAE of valid set:\", MAE_valid)\n",
        "print(\"RMSE of valid set:\", y_valid_rmse)\n",
        "print(\"R2 score of valid set\", r2_valid)\n",
        "print(\"MRE of valid set:\", MRE_valid)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean value of MAE of training set 4.7312375872265156\n",
            "Standard deviation of MAE of training set 0.13612477725080688\n",
            "Mean value of MAE of test set 6.84342568138626\n",
            "Standard deviation of MAE of test set 0.5280196177258322\n",
            "\n",
            "Mean value of RMSE of training set 6.252295088804634\n",
            "Standard deviation of RMSE of training set 0.1629426712959031\n",
            "Mean value of RMSE of test set 8.956238995024808\n",
            "Standard deviation of RMSE of test set 0.770848659470914\n",
            "\n",
            "Mean value of R2 of training set 0.8711185168504404\n",
            "Standard deviation of R2 of training set 0.009421943238565786\n",
            "Mean value of R2 of test set 0.723972581350106\n",
            "Standard deviation of R2 of test set 0.06456672982961281\n",
            "\n",
            "Mean value of MRE of training set 0.1582342594080174\n",
            "Standard deviation of MRE of training set 0.004907703548692283\n",
            "Mean value of MRE of test set 0.22963715049702124\n",
            "Standard deviation of MRE of test set 0.01978218969741712\n",
            "\n",
            "MAE of valid set: 5.9634102333496095\n",
            "RMSE of valid set: 7.369704510447157\n",
            "R2 score of valid set 0.8169644606099243\n",
            "MRE of valid set: 0.21220792607880984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxNoznXg7WeT"
      },
      "source": [
        "Parity={'Predict Data':y_pred_all,'Test Data':y_test_all}\n",
        "df = pd.DataFrame(Parity, columns= ['Predict Data', 'Test Data'])\n",
        "df.to_csv (r'/content/export_dataframe_XGBoost_opt.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "GuplwoaQoXyK",
        "outputId": "82c8817d-6750-413f-909e-2286bfb71fdc"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_test_all, y_pred_all, 'bo')\n",
        "py.ylim(0, 100)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8RqjjeQnoRtA",
        "outputId": "6732f027-d8d7-4735-96d7-33bcb8aecc75"
      },
      "source": [
        "from xgboost import plot_importance\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "f4qdfxcnvGxq",
        "outputId": "719fa82b-6c8a-4b8d-f456-b940e6612d40"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_valid, y_valid_predict, 'bo')\n",
        "py.ylim(0, 100)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}