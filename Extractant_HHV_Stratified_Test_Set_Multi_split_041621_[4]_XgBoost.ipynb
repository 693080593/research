{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extractant HHV Stratified Test Set Multi-split 041621 [4]_XgBoost.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNoI9zOABwRHY4LwK5GaUKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/693080593/research/blob/master/Extractant_HHV_Stratified_Test_Set_Multi_split_041621_%5B4%5D_XgBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxqhn92z_ts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9490aace-8b38-4f93-f211-b5237415347a"
      },
      "source": [
        "# Import libraries necessary for this project\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import supplementary visualizations code visuals.py\n",
        "import visuals as vs\n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Extrantant Type Effect on Biocrude Yield HHV ER 041621 Stratified Test.csv')\n",
        "Original_Oil_HHV = data['Bio-crude Oil HHV']\n",
        "Original_Features = data.drop(['Bio-crude Oil Yield','Bio-crude Oil HHV','Bio-crude Oil ER'], axis = 1)\n",
        "\n",
        "data_figure = data.drop(['Bio-crude Oil Yield','Bio-crude Oil ER','Group'], axis = 1)\n",
        "\n",
        "# Success\n",
        "print (\"Bio-crude dataset has {} data points with {} variables each.\".format(*data_figure.shape))\n",
        "data_figure.shape\n",
        "\n",
        "data_figure[:540:11]\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bio-crude dataset has 316 data points with 17 variables each.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dichloromethane</th>\n",
              "      <th>Toluene</th>\n",
              "      <th>Acetone</th>\n",
              "      <th>Tetrahydrofuran</th>\n",
              "      <th>Methanol</th>\n",
              "      <th>Hexane</th>\n",
              "      <th>Diethyl Ether</th>\n",
              "      <th>Chloroform</th>\n",
              "      <th>Ethyl Acetate</th>\n",
              "      <th>Lipid</th>\n",
              "      <th>Protein</th>\n",
              "      <th>Cellulose</th>\n",
              "      <th>Hemicellulose</th>\n",
              "      <th>Carbohydrate</th>\n",
              "      <th>Lignin</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Bio-crude Oil HHV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.521739</td>\n",
              "      <td>40.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17.830000</td>\n",
              "      <td>30.060000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>34.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.760000</td>\n",
              "      <td>14.260000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.970000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>34.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>35.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>2.300000</td>\n",
              "      <td>61.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>33.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>46.940000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.470000</td>\n",
              "      <td>32.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>36.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.325300</td>\n",
              "      <td>25.576050</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.678850</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>35.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>67.440000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.280000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.080000</td>\n",
              "      <td>38.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.501066</td>\n",
              "      <td>35.378686</td>\n",
              "      <td>36.937929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.190000</td>\n",
              "      <td>36.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>51.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.100000</td>\n",
              "      <td>33.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>33.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>4.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.100000</td>\n",
              "      <td>32.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>36.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.910000</td>\n",
              "      <td>38.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.620000</td>\n",
              "      <td>60.060000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.480000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>36.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>27.200000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>47.500000</td>\n",
              "      <td>25.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>46.200000</td>\n",
              "      <td>19.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>24.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.624923</td>\n",
              "      <td>25.624092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.592592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.630000</td>\n",
              "      <td>35.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>35.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>33.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>61.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>40.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>91.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>20.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.480000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.520000</td>\n",
              "      <td>30.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.411765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.705882</td>\n",
              "      <td>34.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>25.950000</td>\n",
              "      <td>12.720000</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>34.570000</td>\n",
              "      <td>4.780000</td>\n",
              "      <td>30.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>13.310000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49.570000</td>\n",
              "      <td>36.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.702310</td>\n",
              "      <td>35.327294</td>\n",
              "      <td>2.315554</td>\n",
              "      <td>22.867338</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>27.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Dichloromethane  Toluene  Acetone  ...     Lignin        Ash  Bio-crude Oil HHV\n",
              "0                100        0        0  ...   0.000000   0.000000              36.00\n",
              "11               100        0        0  ...   0.000000   6.521739              40.80\n",
              "22                 0        0      100  ...   0.000000   2.100000              34.37\n",
              "33               100        0        0  ...   0.000000   7.000000              34.60\n",
              "44               100        0        0  ...   0.000000   6.000000              35.50\n",
              "55                 0        0        0  ...   0.000000   8.700000              33.80\n",
              "66                 0        0      100  ...   0.000000   3.470000              32.20\n",
              "77               100        0        0  ...   0.000000   7.500000              36.00\n",
              "88               100        0        0  ...   0.000000  16.500000              35.92\n",
              "99               100        0        0  ...   0.000000  11.080000              38.28\n",
              "110                0        0        0  ...   0.000000  23.190000              36.65\n",
              "121              100        0        0  ...   0.000000   6.100000              33.70\n",
              "132              100        0        0  ...   0.000000   5.800000              33.70\n",
              "143              100        0        0  ...   0.000000   6.100000              32.10\n",
              "154              100        0        0  ...   0.000000   8.910000              38.29\n",
              "165              100        0        0  ...   0.000000   7.600000              36.80\n",
              "176                0      100        0  ...   5.700000  47.500000              25.80\n",
              "187              100        0        0  ...  23.200000   0.100000              24.30\n",
              "198                0        0        0  ...   0.000000  40.630000              35.30\n",
              "209              100        0        0  ...   0.000000   4.900000              33.10\n",
              "220              100        0        0  ...   0.000000   0.000000              34.06\n",
              "231                0        0      100  ...  27.700000   1.100000              40.40\n",
              "242              100        0        0  ...   0.000000   0.000000              33.80\n",
              "253                0        0      100  ...   0.700000   0.500000              20.90\n",
              "264              100        0        0  ...   0.000000   2.520000              30.57\n",
              "275              100        0        0  ...   0.000000  44.705882              34.90\n",
              "286              100        0        0  ...  34.570000   4.780000              30.05\n",
              "297              100        0        0  ...   0.000000  49.570000              36.97\n",
              "308              100        0        0  ...  22.867338   0.620000              27.97\n",
              "\n",
              "[29 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXrrKtldEvO1"
      },
      "source": [
        "# MinMaxScale\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#from pandas import DataFrame\n",
        "\n",
        "#data_MinMax = data2.drop(['Lipid','Protein','Cellulose','Hemicellulose','Carbohydrate','Lignin','Ash','Bio-crude Oil Yield','Group'], axis = 1)\n",
        "\n",
        "#scaler = MinMaxScaler()\n",
        "\n",
        "#print(scaler.fit(data_MinMax))\n",
        "\n",
        "#print(scaler.data_max_)\n",
        "#print(scaler.data_min_)\n",
        "\n",
        "#data_MinMax3 = scaler.transform(data_MinMax)\n",
        "\n",
        "#data_MinMax2 = pd.DataFrame(data = data_MinMax3*100,  columns =[\"Temperature\"])\n",
        "\n",
        "#print(data_MinMax2)\n",
        "\n",
        "#Original_Features = pd.concat([data2['Lipid'],data2['Protein'],data2['Cellulose'],data2['Hemicellulose'],data2['Carbohydrate'],data2['Lignin'],data2['Ash'],data_MinMax2, data2['Group']], axis=1)\n",
        "\n",
        "#data=pd.concat([Original_Features, data2['Bio-crude Oil Yield']], axis=1)\n",
        "\n",
        "#data_figure_new=data.drop('Group', axis = 1)\n",
        "\n",
        "#data[:517:11]\n",
        "\n",
        "#Original_Features[:511:11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhbMxqOIQfmS"
      },
      "source": [
        "import numpy as np\n",
        "# The mean relative error (MRE) is commonly used to measure the predictive accuracy of models.\n",
        "\n",
        "def performance_metric(y_true, y_predict):\n",
        "  \"\"\"Calculates and returns the performance score between \n",
        "        true and predicted values based on the metric chosen.\"\"\"\n",
        "  # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
        "\n",
        "  return np.mean(np.abs(y_true-y_predict))/np.mean(y_true)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO52jy5G0vdu"
      },
      "source": [
        "# No use.\n",
        "for j in range(0,201,1):\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_Yields, y_valid = train_test_split(Original_Features, Original_Oil_Yields, test_size = 0.1, stratify=group2, random_state=j)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "\n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "\n",
        "  cnt = 1\n",
        "  \n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  MRE_train_all=[]\n",
        "  MRE_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(1,50,1):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_Yields, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    model = XGBRegressor(silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    MRE_train = performance_metric(y_train, y_train_predict)\n",
        "    MRE_test = performance_metric(y_test, y_test_predict)\n",
        "\n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    MRE_train_all.append(MRE_train)\n",
        "    MRE_test_all.append(MRE_test)\n",
        "    \n",
        "  # Predict validation set\n",
        "  model.fit(Features_new, Oil_Yields)\n",
        "\n",
        "  y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  MRE_valid = performance_metric(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  print(\"R2 score of valid set\", r2_valid)\n",
        "  print(\"Max Values of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)\n",
        "  print(\"Difference Values of R2 of training and test sets\", np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  print(\"\")\n",
        "  #print(\"Mean value of MRE of training set\", np.mean(MRE_train_all))\n",
        "  #print(\"Mean value of MRE of test set\", np.mean(MRE_test_all))\n",
        "  #print(\"MRE of valid set:\", MRE_valid)\n",
        "  #print(\"Min Values of MRE of test set\", min(MRE_test_all))\n",
        "  #print(\"Standard deviation of MRE of test set\", np.std(MRE_test_all))\n",
        "  #print(\"Difference Values of MRE of training and test sets\", np.mean(MRE_train_all)-np.mean(MRE_test_all))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikEpsH7MUI68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e590544-5af1-4414-d332-a32649ad10c5"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "from math import sqrt\n",
        "from sklearn import metrics\n",
        "\n",
        "group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "# TODO: Shuffle and split the data into training and testing subsets\n",
        "Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "\n",
        "X_valid_new=X_valid.drop('Group', axis=1)\n",
        "\n",
        "Features_new=Features.drop('Group', axis=1)\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "MAE_train_all=[]\n",
        "MAE_test_all=[]\n",
        "y_train_rmse_all=[]\n",
        "y_test_rmse_all=[]\n",
        "r2_train_all=[]\n",
        "r2_test_all=[]\n",
        "MRE_train_all=[]\n",
        "MRE_test_all=[]\n",
        "y_test_list=[]\n",
        "y_pred_list=[]\n",
        "\n",
        "for i in range(5000,6000,10):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "  model = XGBRegressor(silent = True)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "    \n",
        "  y_train_predict = model.predict(X_train)\n",
        "  y_test_predict = model.predict(X_test)\n",
        "\n",
        "  MAE_train = metrics.mean_absolute_error(y_train, y_train_predict)\n",
        "  MAE_test = metrics.mean_absolute_error(y_test, y_test_predict)\n",
        "    \n",
        "  y_train_rmse = sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
        "  y_test_rmse = sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
        "    \n",
        "  r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "  r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "\n",
        "  MRE_train = performance_metric(y_train, y_train_predict)\n",
        "  MRE_test = performance_metric(y_test, y_test_predict)\n",
        "\n",
        "  cnt += 1\n",
        "  MAE_train_all.append(MAE_train)\n",
        "  MAE_test_all.append(MAE_test)\n",
        "  y_train_rmse_all.append(y_train_rmse)\n",
        "  y_test_rmse_all.append(y_test_rmse)\n",
        "  r2_train_all.append(r2_train)\n",
        "  r2_test_all.append(r2_test)\n",
        "  MRE_train_all.append(MRE_train)\n",
        "  MRE_test_all.append(MRE_test)\n",
        "\n",
        "  # For drawing plot\n",
        "  y_test_list.append(y_test.values)\n",
        "  y_pred_list.append(y_test_predict)  \n",
        "\n",
        "y_test_all=np.concatenate(y_test_list, axis=0)\n",
        "y_pred_all=np.concatenate(y_pred_list, axis=0)\n",
        "\n",
        "print(\"Mean value of MAE of training set\", np.mean(MAE_train_all))\n",
        "print(\"Standard deviation of MAE of training set\", np.std(MAE_train_all))\n",
        "print(\"Mean value of MAE of test set\", np.mean(MAE_test_all))\n",
        "print(\"Standard deviation of MAE of test set\", np.std(MAE_test_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of RMSE of training set\", np.mean(y_train_rmse_all))\n",
        "print(\"Standard deviation of RMSE of training set\", np.std(y_train_rmse_all))\n",
        "print(\"Mean value of RMSE of test set\", np.mean(y_test_rmse_all))\n",
        "print(\"Standard deviation of RMSE of test set\", np.std(y_test_rmse_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "print(\"Standard deviation of R2 of training set\", np.std(r2_train_all))\n",
        "print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "#print(\"Value of R2 of test set\", r2_test_all)\n",
        "print(\"\")\n",
        "print(\"Mean value of MRE of training set\", np.mean(MRE_train_all))\n",
        "print(\"Standard deviation of MRE of training set\", np.std(MRE_train_all))\n",
        "print(\"Mean value of MRE of test set\", np.mean(MRE_test_all))\n",
        "print(\"Standard deviation of MRE of test set\", np.std(MRE_test_all))\n",
        "\n",
        "print(\"\")\n",
        "# Predict validation set\n",
        "model.fit(Features_new, Oil_HHV)\n",
        "\n",
        "y_valid_predict = model.predict(X_valid_new)\n",
        "\n",
        "MAE_valid = metrics.mean_absolute_error(y_valid, y_valid_predict)\n",
        "y_valid_rmse = sqrt(metrics.mean_squared_error(y_valid, y_valid_predict))\n",
        "r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "MRE_valid = performance_metric(y_valid, y_valid_predict)\n",
        "\n",
        "print(\"MAE of valid set:\", MAE_valid)\n",
        "print(\"RMSE of valid set:\", y_valid_rmse)\n",
        "print(\"R2 score of valid set\", r2_valid)\n",
        "print(\"MRE of valid set:\", MRE_valid)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean value of MAE of training set 1.2749806572774443\n",
            "Standard deviation of MAE of training set 0.05642658004101939\n",
            "Mean value of MAE of test set 2.3295810256194414\n",
            "Standard deviation of MAE of test set 0.27708715237472253\n",
            "\n",
            "Mean value of RMSE of training set 1.7147676671772598\n",
            "Standard deviation of RMSE of training set 0.08088164073261468\n",
            "Mean value of RMSE of test set 3.2671033180036595\n",
            "Standard deviation of RMSE of test set 0.469614817511136\n",
            "\n",
            "Mean value of R2 of training set 0.8230302554392899\n",
            "Standard deviation of R2 of training set 0.01594912058068607\n",
            "Mean value of R2 of test set 0.33682558020646686\n",
            "Standard deviation of R2 of test set 0.17665355497464583\n",
            "\n",
            "Mean value of MRE of training set 0.03780475807848835\n",
            "Standard deviation of MRE of training set 0.0016749187425234265\n",
            "Mean value of MRE of test set 0.0690762992216633\n",
            "Standard deviation of MRE of test set 0.008396953721059584\n",
            "\n",
            "MAE of valid set: 2.628640412197113\n",
            "RMSE of valid set: 3.213031321846453\n",
            "R2 score of valid set 0.5565559149296786\n",
            "MRE of valid set: 0.07737081109289233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "lDaa-0yLR8Tm",
        "outputId": "93130251-7ef6-4f36-aa0d-9187f122d8b0"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_test_all, y_pred_all, 'bo')\n",
        "py.ylim(20, 43)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huXzQLHuaDz8"
      },
      "source": [
        "Parity={'Predict Data':y_pred_all,'Test Data':y_test_all}\n",
        "df = pd.DataFrame(Parity, columns= ['Predict Data', 'Test Data'])\n",
        "df.to_csv (r'/content/export_dataframe_XGBoost.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yDZJ9s3cRcnb",
        "outputId": "88611816-4f40-4549-dad6-f4e20cc81279"
      },
      "source": [
        "from xgboost import plot_importance\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5z6KUkJkmRPz",
        "outputId": "4a9cc8be-f110-4cc7-cd3e-34ae07b02ac4"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_valid, y_valid_predict, 'bo')\n",
        "py.ylim(20, 43)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQoqEc6c6MLW"
      },
      "source": [
        "# n_estimators 参数的最佳取值(10, 200, 11)\n",
        "\n",
        "for j in range(10, 200, 10):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': j, 'gamma': 0, 'max_depth': 5, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JNuZUmg-UEt"
      },
      "source": [
        "# max_depth 参数的最佳取值(1, 20, 10)\n",
        "\n",
        "for j in range(1, 20, 1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0, 'max_depth': j, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU6KaKpAEUrg"
      },
      "source": [
        "# min_child_weight 参数的最佳取值(1, 10, 10)\n",
        "\n",
        "for j in range(0,11,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0, 'max_depth': 2, 'min_child_weight': j,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtEJ7EmrSVQT"
      },
      "source": [
        "# gamma 参数的最佳取值(0, 0.2, 11)\n",
        "\n",
        "for j in range(21,41,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': j/100, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6000000000000001, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/100)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSYJ-5AbTFvo"
      },
      "source": [
        "# subsample 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(9430,9450,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': j/10000, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10000)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_sddf_xXIKI"
      },
      "source": [
        "# colsample_bytree 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(0,11,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': j/10, 'colsample_bylevel': 1, 'subsample': 0.9438, 'reg_lambda': 0.7000000000000001, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaH2veECXsK4"
      },
      "source": [
        "# reg_lambda 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(510,530,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 0.3, 'colsample_bylevel': 1, 'subsample': 0.9438, 'reg_lambda': j/10000, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10000)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbm3tTrlZw7I"
      },
      "source": [
        "# reg_alpha 参数的最佳取值(0, 1, 11)\n",
        "\n",
        "for j in range(0,11,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 0.3, 'colsample_bylevel': 1, 'subsample': 0.9438, 'reg_lambda': 0.0519, 'reg_alpha': j/10,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/10)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC2pDPB0bVXx"
      },
      "source": [
        "# eta 参数的最佳取值(-2, 0, 10)\n",
        "\n",
        "for j in range(0,10,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': j/100, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 0.3, 'colsample_bylevel': 1, 'subsample': 0.9438, 'reg_lambda': 0.0519, 'reg_alpha': 0,\n",
        "                'seed': 33}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j/100)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuE6JW9eb6pW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8428eb3b-0a09-4cc7-d7f6-2de0fc89882a"
      },
      "source": [
        "# seed 参数的最佳取值(0, 100, 1)\n",
        "\n",
        "for j in range(0,201,1):\n",
        "\n",
        "  # TODO: Import 'RandomForestRegressor'\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  \n",
        "  # TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "  from math import sqrt\n",
        "  from sklearn import metrics\n",
        "  \n",
        "  group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "  # TODO: Shuffle and split the data into training and testing subsets\n",
        "  Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "  \n",
        "  X_valid_new=X_valid.drop('Group', axis=1)\n",
        "  \n",
        "  Features_new=Features.drop('Group', axis=1)\n",
        "  \n",
        "  cnt = 1\n",
        "\n",
        "  r2_train_all=[]\n",
        "  r2_test_all=[]\n",
        "  \n",
        "  # split()  method generate indices to split data into training and test set.\n",
        "  \n",
        "  for i in range(5000,6000,10):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "    other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "                'colsample_bytree': 0.3, 'colsample_bylevel': 1, 'subsample': 0.9438, 'reg_lambda': 0.0519, 'reg_alpha': 0,\n",
        "                'seed': j}\n",
        "\n",
        "    model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_train_predict = model.predict(X_train)\n",
        "    y_test_predict = model.predict(X_test)\n",
        "    \n",
        "    r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "    r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "    \n",
        "    cnt += 1\n",
        "    \n",
        "    r2_train_all.append(r2_train)\n",
        "    r2_test_all.append(r2_test) \n",
        "    \n",
        "  # Predict validation set\n",
        "  #model.fit(Features_new, Oil_HHV)\n",
        "  #y_valid_predict = model.predict(X_valid_new)\n",
        "  \n",
        "  #r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "\n",
        "  print(j)\n",
        "  print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "  print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "  #print(\"R2 score of valid set\", r2_valid)\n",
        "  #print(\"Max value of R2 of test set\", max(r2_test_all))\n",
        "  print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "  print(\"Train-Test:\",np.mean(r2_train_all)-np.mean(r2_test_all))\n",
        "  #print(\"Testmax-Valid:\",max(r2_test_all)-r2_valid)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Mean value of R2 of training set 0.6477382657525684\n",
            "Mean value of R2 of test set 0.3580261905170569\n",
            "Standard deviation of R2 of test set 0.14053469288044562\n",
            "Train-Test: 0.2897120752355115\n",
            "1\n",
            "Mean value of R2 of training set 0.6442411426904961\n",
            "Mean value of R2 of test set 0.3639034439653092\n",
            "Standard deviation of R2 of test set 0.15241687112928723\n",
            "Train-Test: 0.28033769872518693\n",
            "2\n",
            "Mean value of R2 of training set 0.6378713079716417\n",
            "Mean value of R2 of test set 0.3540671471321867\n",
            "Standard deviation of R2 of test set 0.13732071738716514\n",
            "Train-Test: 0.28380416083945503\n",
            "3\n",
            "Mean value of R2 of training set 0.6446110416667016\n",
            "Mean value of R2 of test set 0.364419549157019\n",
            "Standard deviation of R2 of test set 0.13686957504000857\n",
            "Train-Test: 0.28019149250968256\n",
            "4\n",
            "Mean value of R2 of training set 0.6349631374480137\n",
            "Mean value of R2 of test set 0.36352496935471224\n",
            "Standard deviation of R2 of test set 0.14404708934565985\n",
            "Train-Test: 0.27143816809330146\n",
            "5\n",
            "Mean value of R2 of training set 0.6421229732533967\n",
            "Mean value of R2 of test set 0.3606506001467716\n",
            "Standard deviation of R2 of test set 0.13564166070917222\n",
            "Train-Test: 0.28147237310662515\n",
            "6\n",
            "Mean value of R2 of training set 0.6433362590474384\n",
            "Mean value of R2 of test set 0.3673388431012331\n",
            "Standard deviation of R2 of test set 0.14863775571886453\n",
            "Train-Test: 0.2759974159462053\n",
            "7\n",
            "Mean value of R2 of training set 0.6441958378796394\n",
            "Mean value of R2 of test set 0.3487303356332347\n",
            "Standard deviation of R2 of test set 0.14131316123604332\n",
            "Train-Test: 0.2954655022464047\n",
            "8\n",
            "Mean value of R2 of training set 0.6405157630295519\n",
            "Mean value of R2 of test set 0.3657831884292913\n",
            "Standard deviation of R2 of test set 0.13333415865820275\n",
            "Train-Test: 0.2747325746002606\n",
            "9\n",
            "Mean value of R2 of training set 0.6356379975158144\n",
            "Mean value of R2 of test set 0.35716818396821315\n",
            "Standard deviation of R2 of test set 0.1449929391856085\n",
            "Train-Test: 0.27846981354760125\n",
            "10\n",
            "Mean value of R2 of training set 0.6413983147737267\n",
            "Mean value of R2 of test set 0.3690831198812478\n",
            "Standard deviation of R2 of test set 0.14080091934249692\n",
            "Train-Test: 0.27231519489247885\n",
            "11\n",
            "Mean value of R2 of training set 0.6405015920402216\n",
            "Mean value of R2 of test set 0.3452208041798468\n",
            "Standard deviation of R2 of test set 0.14149955899935726\n",
            "Train-Test: 0.2952807878603748\n",
            "12\n",
            "Mean value of R2 of training set 0.6344959233193758\n",
            "Mean value of R2 of test set 0.3669902429463605\n",
            "Standard deviation of R2 of test set 0.13582967692380415\n",
            "Train-Test: 0.26750568037301525\n",
            "13\n",
            "Mean value of R2 of training set 0.6397487906795021\n",
            "Mean value of R2 of test set 0.3652930456364032\n",
            "Standard deviation of R2 of test set 0.14898666576859196\n",
            "Train-Test: 0.2744557450430989\n",
            "14\n",
            "Mean value of R2 of training set 0.6334776720954123\n",
            "Mean value of R2 of test set 0.36386379919694356\n",
            "Standard deviation of R2 of test set 0.12893112556288677\n",
            "Train-Test: 0.2696138728984687\n",
            "15\n",
            "Mean value of R2 of training set 0.6375912123404714\n",
            "Mean value of R2 of test set 0.3632842552560192\n",
            "Standard deviation of R2 of test set 0.134421287335372\n",
            "Train-Test: 0.27430695708445224\n",
            "16\n",
            "Mean value of R2 of training set 0.649018231628107\n",
            "Mean value of R2 of test set 0.35910119790777467\n",
            "Standard deviation of R2 of test set 0.13983758448685782\n",
            "Train-Test: 0.28991703372033234\n",
            "17\n",
            "Mean value of R2 of training set 0.6425983279505705\n",
            "Mean value of R2 of test set 0.34972932915400873\n",
            "Standard deviation of R2 of test set 0.13484379084949424\n",
            "Train-Test: 0.29286899879656175\n",
            "18\n",
            "Mean value of R2 of training set 0.6369384332399988\n",
            "Mean value of R2 of test set 0.3655571507613658\n",
            "Standard deviation of R2 of test set 0.1351079137014094\n",
            "Train-Test: 0.27138128247863297\n",
            "19\n",
            "Mean value of R2 of training set 0.6396049235818707\n",
            "Mean value of R2 of test set 0.370949554334556\n",
            "Standard deviation of R2 of test set 0.13981676961073133\n",
            "Train-Test: 0.2686553692473147\n",
            "20\n",
            "Mean value of R2 of training set 0.6418557045798735\n",
            "Mean value of R2 of test set 0.36945033657990495\n",
            "Standard deviation of R2 of test set 0.141264380010981\n",
            "Train-Test: 0.27240536799996856\n",
            "21\n",
            "Mean value of R2 of training set 0.6372787603455882\n",
            "Mean value of R2 of test set 0.37233403719572417\n",
            "Standard deviation of R2 of test set 0.13324964961106345\n",
            "Train-Test: 0.264944723149864\n",
            "22\n",
            "Mean value of R2 of training set 0.6466793359385821\n",
            "Mean value of R2 of test set 0.35878840367297715\n",
            "Standard deviation of R2 of test set 0.14178157564031066\n",
            "Train-Test: 0.2878909322656049\n",
            "23\n",
            "Mean value of R2 of training set 0.6450306987247656\n",
            "Mean value of R2 of test set 0.3585433029879954\n",
            "Standard deviation of R2 of test set 0.1452741120847288\n",
            "Train-Test: 0.2864873957367702\n",
            "24\n",
            "Mean value of R2 of training set 0.6459885456156245\n",
            "Mean value of R2 of test set 0.3670640657668147\n",
            "Standard deviation of R2 of test set 0.13653107988844332\n",
            "Train-Test: 0.27892447984880975\n",
            "25\n",
            "Mean value of R2 of training set 0.6452361352247945\n",
            "Mean value of R2 of test set 0.3624087749929244\n",
            "Standard deviation of R2 of test set 0.1364116667889085\n",
            "Train-Test: 0.2828273602318701\n",
            "26\n",
            "Mean value of R2 of training set 0.629880071300288\n",
            "Mean value of R2 of test set 0.32855959982806676\n",
            "Standard deviation of R2 of test set 0.15069059571858187\n",
            "Train-Test: 0.30132047147222124\n",
            "27\n",
            "Mean value of R2 of training set 0.6364264303530137\n",
            "Mean value of R2 of test set 0.35094799936270044\n",
            "Standard deviation of R2 of test set 0.13781528646462002\n",
            "Train-Test: 0.2854784309903133\n",
            "28\n",
            "Mean value of R2 of training set 0.6358029520386317\n",
            "Mean value of R2 of test set 0.3522653350695105\n",
            "Standard deviation of R2 of test set 0.13917932342198602\n",
            "Train-Test: 0.28353761696912116\n",
            "29\n",
            "Mean value of R2 of training set 0.6482689463046821\n",
            "Mean value of R2 of test set 0.36204335313139324\n",
            "Standard deviation of R2 of test set 0.14116091010991008\n",
            "Train-Test: 0.2862255931732889\n",
            "30\n",
            "Mean value of R2 of training set 0.6535449704140681\n",
            "Mean value of R2 of test set 0.36213874945406715\n",
            "Standard deviation of R2 of test set 0.14489625114661828\n",
            "Train-Test: 0.29140622096000096\n",
            "31\n",
            "Mean value of R2 of training set 0.6376447346824399\n",
            "Mean value of R2 of test set 0.35092708975335685\n",
            "Standard deviation of R2 of test set 0.14654625512062766\n",
            "Train-Test: 0.286717644929083\n",
            "32\n",
            "Mean value of R2 of training set 0.6410150412245436\n",
            "Mean value of R2 of test set 0.35157832783377174\n",
            "Standard deviation of R2 of test set 0.14608895016841594\n",
            "Train-Test: 0.2894367133907718\n",
            "33\n",
            "Mean value of R2 of training set 0.6404063247624784\n",
            "Mean value of R2 of test set 0.36969005297938073\n",
            "Standard deviation of R2 of test set 0.1304226743368974\n",
            "Train-Test: 0.27071627178309765\n",
            "34\n",
            "Mean value of R2 of training set 0.642756987402822\n",
            "Mean value of R2 of test set 0.3616852605749161\n",
            "Standard deviation of R2 of test set 0.1376506608442657\n",
            "Train-Test: 0.28107172682790593\n",
            "35\n",
            "Mean value of R2 of training set 0.6321006082456544\n",
            "Mean value of R2 of test set 0.3676467718656158\n",
            "Standard deviation of R2 of test set 0.1363123428183661\n",
            "Train-Test: 0.2644538363800386\n",
            "36\n",
            "Mean value of R2 of training set 0.6387375470809886\n",
            "Mean value of R2 of test set 0.3475638611652139\n",
            "Standard deviation of R2 of test set 0.14205987427783137\n",
            "Train-Test: 0.2911736859157747\n",
            "37\n",
            "Mean value of R2 of training set 0.6345889883656216\n",
            "Mean value of R2 of test set 0.3639348167022212\n",
            "Standard deviation of R2 of test set 0.13698162201680353\n",
            "Train-Test: 0.2706541716634004\n",
            "38\n",
            "Mean value of R2 of training set 0.6417566195681877\n",
            "Mean value of R2 of test set 0.3559530953823377\n",
            "Standard deviation of R2 of test set 0.1499507482494787\n",
            "Train-Test: 0.28580352418585003\n",
            "39\n",
            "Mean value of R2 of training set 0.6349681374607044\n",
            "Mean value of R2 of test set 0.3719128060154217\n",
            "Standard deviation of R2 of test set 0.13879930299608448\n",
            "Train-Test: 0.26305533144528265\n",
            "40\n",
            "Mean value of R2 of training set 0.6454451130284738\n",
            "Mean value of R2 of test set 0.3515892466318051\n",
            "Standard deviation of R2 of test set 0.13558698330562188\n",
            "Train-Test: 0.2938558663966688\n",
            "41\n",
            "Mean value of R2 of training set 0.6285685272436722\n",
            "Mean value of R2 of test set 0.3410702601362426\n",
            "Standard deviation of R2 of test set 0.13713906650104998\n",
            "Train-Test: 0.2874982671074296\n",
            "42\n",
            "Mean value of R2 of training set 0.6371690516818288\n",
            "Mean value of R2 of test set 0.3562217863732192\n",
            "Standard deviation of R2 of test set 0.140781873749048\n",
            "Train-Test: 0.2809472653086096\n",
            "43\n",
            "Mean value of R2 of training set 0.6427976422613908\n",
            "Mean value of R2 of test set 0.3680227735755971\n",
            "Standard deviation of R2 of test set 0.14549804021558563\n",
            "Train-Test: 0.2747748686857937\n",
            "44\n",
            "Mean value of R2 of training set 0.6439068300377628\n",
            "Mean value of R2 of test set 0.37539408615350317\n",
            "Standard deviation of R2 of test set 0.13681532622521372\n",
            "Train-Test: 0.26851274388425966\n",
            "45\n",
            "Mean value of R2 of training set 0.6343785389685123\n",
            "Mean value of R2 of test set 0.355795141722588\n",
            "Standard deviation of R2 of test set 0.13381699983640585\n",
            "Train-Test: 0.27858339724592424\n",
            "46\n",
            "Mean value of R2 of training set 0.6400698605194849\n",
            "Mean value of R2 of test set 0.3629606687952868\n",
            "Standard deviation of R2 of test set 0.13521220690192604\n",
            "Train-Test: 0.27710919172419807\n",
            "47\n",
            "Mean value of R2 of training set 0.631523721883449\n",
            "Mean value of R2 of test set 0.3574132874210491\n",
            "Standard deviation of R2 of test set 0.1477216121621978\n",
            "Train-Test: 0.27411043446239985\n",
            "48\n",
            "Mean value of R2 of training set 0.6371778630015903\n",
            "Mean value of R2 of test set 0.35590890489991045\n",
            "Standard deviation of R2 of test set 0.14466328368952588\n",
            "Train-Test: 0.28126895810167984\n",
            "49\n",
            "Mean value of R2 of training set 0.6391292954455474\n",
            "Mean value of R2 of test set 0.3553992163809452\n",
            "Standard deviation of R2 of test set 0.15036671504171745\n",
            "Train-Test: 0.28373007906460224\n",
            "50\n",
            "Mean value of R2 of training set 0.6442428668557768\n",
            "Mean value of R2 of test set 0.35743175101709357\n",
            "Standard deviation of R2 of test set 0.14266885071284222\n",
            "Train-Test: 0.28681111583868324\n",
            "51\n",
            "Mean value of R2 of training set 0.6462965212342145\n",
            "Mean value of R2 of test set 0.37140492346039733\n",
            "Standard deviation of R2 of test set 0.14406937829353586\n",
            "Train-Test: 0.2748915977738172\n",
            "52\n",
            "Mean value of R2 of training set 0.6402073375464361\n",
            "Mean value of R2 of test set 0.36851948564328585\n",
            "Standard deviation of R2 of test set 0.1411187600516632\n",
            "Train-Test: 0.27168785190315026\n",
            "53\n",
            "Mean value of R2 of training set 0.6399982595990675\n",
            "Mean value of R2 of test set 0.36316035466817054\n",
            "Standard deviation of R2 of test set 0.13529582605462018\n",
            "Train-Test: 0.276837904930897\n",
            "54\n",
            "Mean value of R2 of training set 0.6384963921545005\n",
            "Mean value of R2 of test set 0.3594479875839338\n",
            "Standard deviation of R2 of test set 0.13529557444161805\n",
            "Train-Test: 0.2790484045705667\n",
            "55\n",
            "Mean value of R2 of training set 0.6411202301816177\n",
            "Mean value of R2 of test set 0.3567440342407028\n",
            "Standard deviation of R2 of test set 0.14449256859297388\n",
            "Train-Test: 0.2843761959409149\n",
            "56\n",
            "Mean value of R2 of training set 0.6402467576494207\n",
            "Mean value of R2 of test set 0.3559851378080332\n",
            "Standard deviation of R2 of test set 0.14414880848730452\n",
            "Train-Test: 0.28426161984138754\n",
            "57\n",
            "Mean value of R2 of training set 0.644355304980714\n",
            "Mean value of R2 of test set 0.3575220054441248\n",
            "Standard deviation of R2 of test set 0.14243323968268357\n",
            "Train-Test: 0.2868332995365892\n",
            "58\n",
            "Mean value of R2 of training set 0.6409123009892888\n",
            "Mean value of R2 of test set 0.35735258854560237\n",
            "Standard deviation of R2 of test set 0.1393761365372952\n",
            "Train-Test: 0.2835597124436864\n",
            "59\n",
            "Mean value of R2 of training set 0.6415164169915841\n",
            "Mean value of R2 of test set 0.35112030436119535\n",
            "Standard deviation of R2 of test set 0.13758712144084217\n",
            "Train-Test: 0.2903961126303888\n",
            "60\n",
            "Mean value of R2 of training set 0.6324266055597383\n",
            "Mean value of R2 of test set 0.3403999452237857\n",
            "Standard deviation of R2 of test set 0.135387847963698\n",
            "Train-Test: 0.2920266603359526\n",
            "61\n",
            "Mean value of R2 of training set 0.6366448990846155\n",
            "Mean value of R2 of test set 0.35596461715305927\n",
            "Standard deviation of R2 of test set 0.13801459723009624\n",
            "Train-Test: 0.28068028193155625\n",
            "62\n",
            "Mean value of R2 of training set 0.6428013256527464\n",
            "Mean value of R2 of test set 0.3671200890760764\n",
            "Standard deviation of R2 of test set 0.13503807023805245\n",
            "Train-Test: 0.27568123657667\n",
            "63\n",
            "Mean value of R2 of training set 0.645227752996309\n",
            "Mean value of R2 of test set 0.3652917664902351\n",
            "Standard deviation of R2 of test set 0.14800550822779668\n",
            "Train-Test: 0.2799359865060739\n",
            "64\n",
            "Mean value of R2 of training set 0.645471490471817\n",
            "Mean value of R2 of test set 0.37522860579091677\n",
            "Standard deviation of R2 of test set 0.13015349682249172\n",
            "Train-Test: 0.2702428846809002\n",
            "65\n",
            "Mean value of R2 of training set 0.6389070578839255\n",
            "Mean value of R2 of test set 0.3693011786498081\n",
            "Standard deviation of R2 of test set 0.13216533287052115\n",
            "Train-Test: 0.26960587923411744\n",
            "66\n",
            "Mean value of R2 of training set 0.6395369600560441\n",
            "Mean value of R2 of test set 0.3455961002304913\n",
            "Standard deviation of R2 of test set 0.13899485134020387\n",
            "Train-Test: 0.2939408598255528\n",
            "67\n",
            "Mean value of R2 of training set 0.644203591071601\n",
            "Mean value of R2 of test set 0.3472171718781813\n",
            "Standard deviation of R2 of test set 0.1425173028146123\n",
            "Train-Test: 0.29698641919341967\n",
            "68\n",
            "Mean value of R2 of training set 0.6303010278015787\n",
            "Mean value of R2 of test set 0.3506375350108402\n",
            "Standard deviation of R2 of test set 0.13201482412088317\n",
            "Train-Test: 0.2796634927907385\n",
            "69\n",
            "Mean value of R2 of training set 0.6476334463926335\n",
            "Mean value of R2 of test set 0.35967655765832673\n",
            "Standard deviation of R2 of test set 0.1492112596220756\n",
            "Train-Test: 0.2879568887343068\n",
            "70\n",
            "Mean value of R2 of training set 0.625960229323958\n",
            "Mean value of R2 of test set 0.3440215010269736\n",
            "Standard deviation of R2 of test set 0.135980097164261\n",
            "Train-Test: 0.2819387282969844\n",
            "71\n",
            "Mean value of R2 of training set 0.644006036837067\n",
            "Mean value of R2 of test set 0.35770704379201257\n",
            "Standard deviation of R2 of test set 0.1462163682972395\n",
            "Train-Test: 0.28629899304505446\n",
            "72\n",
            "Mean value of R2 of training set 0.637429847708822\n",
            "Mean value of R2 of test set 0.3524908902867325\n",
            "Standard deviation of R2 of test set 0.1430104648224835\n",
            "Train-Test: 0.2849389574220896\n",
            "73\n",
            "Mean value of R2 of training set 0.6482250640140345\n",
            "Mean value of R2 of test set 0.36845537828701624\n",
            "Standard deviation of R2 of test set 0.13859561343845278\n",
            "Train-Test: 0.2797696857270182\n",
            "74\n",
            "Mean value of R2 of training set 0.6425693855890517\n",
            "Mean value of R2 of test set 0.3636930341678027\n",
            "Standard deviation of R2 of test set 0.1457126255421907\n",
            "Train-Test: 0.27887635142124906\n",
            "75\n",
            "Mean value of R2 of training set 0.6529206508840447\n",
            "Mean value of R2 of test set 0.3692237892073306\n",
            "Standard deviation of R2 of test set 0.1358300168739452\n",
            "Train-Test: 0.2836968616767141\n",
            "76\n",
            "Mean value of R2 of training set 0.6370994143165788\n",
            "Mean value of R2 of test set 0.356543372519767\n",
            "Standard deviation of R2 of test set 0.13727495764026473\n",
            "Train-Test: 0.2805560417968118\n",
            "77\n",
            "Mean value of R2 of training set 0.6399713995821978\n",
            "Mean value of R2 of test set 0.3580913798208527\n",
            "Standard deviation of R2 of test set 0.1477999579264705\n",
            "Train-Test: 0.28188001976134514\n",
            "78\n",
            "Mean value of R2 of training set 0.6444574867446174\n",
            "Mean value of R2 of test set 0.3602518345970418\n",
            "Standard deviation of R2 of test set 0.1438047375925353\n",
            "Train-Test: 0.28420565214757565\n",
            "79\n",
            "Mean value of R2 of training set 0.6407145470638999\n",
            "Mean value of R2 of test set 0.36843923048951077\n",
            "Standard deviation of R2 of test set 0.14098617223652826\n",
            "Train-Test: 0.2722753165743891\n",
            "80\n",
            "Mean value of R2 of training set 0.6407398297423889\n",
            "Mean value of R2 of test set 0.36853696875817354\n",
            "Standard deviation of R2 of test set 0.13620838384144185\n",
            "Train-Test: 0.2722028609842153\n",
            "81\n",
            "Mean value of R2 of training set 0.6362688262312842\n",
            "Mean value of R2 of test set 0.35197510101744334\n",
            "Standard deviation of R2 of test set 0.14014832512051215\n",
            "Train-Test: 0.2842937252138409\n",
            "82\n",
            "Mean value of R2 of training set 0.6388860594476169\n",
            "Mean value of R2 of test set 0.3516805917108809\n",
            "Standard deviation of R2 of test set 0.14047183780738803\n",
            "Train-Test: 0.287205467736736\n",
            "83\n",
            "Mean value of R2 of training set 0.643955978890707\n",
            "Mean value of R2 of test set 0.37248251781653435\n",
            "Standard deviation of R2 of test set 0.14792222799344823\n",
            "Train-Test: 0.27147346107417264\n",
            "84\n",
            "Mean value of R2 of training set 0.6378785190929098\n",
            "Mean value of R2 of test set 0.3504153756727394\n",
            "Standard deviation of R2 of test set 0.14388727748774532\n",
            "Train-Test: 0.28746314342017043\n",
            "85\n",
            "Mean value of R2 of training set 0.6470887630111438\n",
            "Mean value of R2 of test set 0.3592618801236902\n",
            "Standard deviation of R2 of test set 0.14682988034444333\n",
            "Train-Test: 0.2878268828874536\n",
            "86\n",
            "Mean value of R2 of training set 0.6405556787354826\n",
            "Mean value of R2 of test set 0.36023377377098287\n",
            "Standard deviation of R2 of test set 0.14425624734943088\n",
            "Train-Test: 0.2803219049644997\n",
            "87\n",
            "Mean value of R2 of training set 0.6430206703914284\n",
            "Mean value of R2 of test set 0.36433843908878477\n",
            "Standard deviation of R2 of test set 0.1443647421712599\n",
            "Train-Test: 0.27868223130264363\n",
            "88\n",
            "Mean value of R2 of training set 0.6499338890312252\n",
            "Mean value of R2 of test set 0.3729435637376778\n",
            "Standard deviation of R2 of test set 0.14019524299752942\n",
            "Train-Test: 0.2769903252935474\n",
            "89\n",
            "Mean value of R2 of training set 0.6398380818119608\n",
            "Mean value of R2 of test set 0.3533090949495313\n",
            "Standard deviation of R2 of test set 0.15196317268154277\n",
            "Train-Test: 0.2865289868624295\n",
            "90\n",
            "Mean value of R2 of training set 0.6457205605163153\n",
            "Mean value of R2 of test set 0.3692087060479751\n",
            "Standard deviation of R2 of test set 0.1423808843970232\n",
            "Train-Test: 0.2765118544683402\n",
            "91\n",
            "Mean value of R2 of training set 0.6334205586579946\n",
            "Mean value of R2 of test set 0.359315080523403\n",
            "Standard deviation of R2 of test set 0.13643184578558162\n",
            "Train-Test: 0.27410547813459163\n",
            "92\n",
            "Mean value of R2 of training set 0.6400413823746834\n",
            "Mean value of R2 of test set 0.35920323927495523\n",
            "Standard deviation of R2 of test set 0.14281960436974653\n",
            "Train-Test: 0.2808381430997282\n",
            "93\n",
            "Mean value of R2 of training set 0.640213557345117\n",
            "Mean value of R2 of test set 0.361514176673693\n",
            "Standard deviation of R2 of test set 0.14822691581767425\n",
            "Train-Test: 0.27869938067142397\n",
            "94\n",
            "Mean value of R2 of training set 0.639931466272597\n",
            "Mean value of R2 of test set 0.3639450654274708\n",
            "Standard deviation of R2 of test set 0.1403200222781333\n",
            "Train-Test: 0.2759864008451262\n",
            "95\n",
            "Mean value of R2 of training set 0.6348975060151237\n",
            "Mean value of R2 of test set 0.3663507685477467\n",
            "Standard deviation of R2 of test set 0.1343236335323282\n",
            "Train-Test: 0.26854673746737706\n",
            "96\n",
            "Mean value of R2 of training set 0.638366745798212\n",
            "Mean value of R2 of test set 0.35725135033831285\n",
            "Standard deviation of R2 of test set 0.1343479090799642\n",
            "Train-Test: 0.2811153954598991\n",
            "97\n",
            "Mean value of R2 of training set 0.6320270710297243\n",
            "Mean value of R2 of test set 0.35233863901498386\n",
            "Standard deviation of R2 of test set 0.14279771538982977\n",
            "Train-Test: 0.2796884320147405\n",
            "98\n",
            "Mean value of R2 of training set 0.6392765647754427\n",
            "Mean value of R2 of test set 0.3564469461348238\n",
            "Standard deviation of R2 of test set 0.13973277315708563\n",
            "Train-Test: 0.2828296186406189\n",
            "99\n",
            "Mean value of R2 of training set 0.6410004525962114\n",
            "Mean value of R2 of test set 0.3647193333879052\n",
            "Standard deviation of R2 of test set 0.14258700344124373\n",
            "Train-Test: 0.2762811192083062\n",
            "100\n",
            "Mean value of R2 of training set 0.6432960170316109\n",
            "Mean value of R2 of test set 0.3591641837369541\n",
            "Standard deviation of R2 of test set 0.141544855765121\n",
            "Train-Test: 0.2841318332946568\n",
            "101\n",
            "Mean value of R2 of training set 0.6374341183125974\n",
            "Mean value of R2 of test set 0.3666535469344967\n",
            "Standard deviation of R2 of test set 0.15138597980431634\n",
            "Train-Test: 0.27078057137810074\n",
            "102\n",
            "Mean value of R2 of training set 0.6428838415298447\n",
            "Mean value of R2 of test set 0.36874759427559395\n",
            "Standard deviation of R2 of test set 0.13314523357736607\n",
            "Train-Test: 0.27413624725425073\n",
            "103\n",
            "Mean value of R2 of training set 0.6349166957980167\n",
            "Mean value of R2 of test set 0.3576297280582709\n",
            "Standard deviation of R2 of test set 0.14175924760491446\n",
            "Train-Test: 0.27728696773974576\n",
            "104\n",
            "Mean value of R2 of training set 0.6439070436717492\n",
            "Mean value of R2 of test set 0.3606975004230996\n",
            "Standard deviation of R2 of test set 0.13808588262013494\n",
            "Train-Test: 0.2832095432486496\n",
            "105\n",
            "Mean value of R2 of training set 0.6460817104173887\n",
            "Mean value of R2 of test set 0.36110912900460135\n",
            "Standard deviation of R2 of test set 0.14920005038719927\n",
            "Train-Test: 0.28497258141278736\n",
            "106\n",
            "Mean value of R2 of training set 0.6374317148944071\n",
            "Mean value of R2 of test set 0.3601105775072545\n",
            "Standard deviation of R2 of test set 0.13546721112728144\n",
            "Train-Test: 0.2773211373871526\n",
            "107\n",
            "Mean value of R2 of training set 0.6419570145531999\n",
            "Mean value of R2 of test set 0.37007407649040064\n",
            "Standard deviation of R2 of test set 0.14047808166090694\n",
            "Train-Test: 0.27188293806279923\n",
            "108\n",
            "Mean value of R2 of training set 0.6440694954005292\n",
            "Mean value of R2 of test set 0.35011570436625405\n",
            "Standard deviation of R2 of test set 0.14774879751732062\n",
            "Train-Test: 0.2939537910342751\n",
            "109\n",
            "Mean value of R2 of training set 0.6429072226356538\n",
            "Mean value of R2 of test set 0.3553297134839961\n",
            "Standard deviation of R2 of test set 0.14244195584081185\n",
            "Train-Test: 0.2875775091516577\n",
            "110\n",
            "Mean value of R2 of training set 0.6414739168077105\n",
            "Mean value of R2 of test set 0.3718200744446053\n",
            "Standard deviation of R2 of test set 0.1386308550526097\n",
            "Train-Test: 0.2696538423631052\n",
            "111\n",
            "Mean value of R2 of training set 0.6363512785087528\n",
            "Mean value of R2 of test set 0.3524078707720962\n",
            "Standard deviation of R2 of test set 0.13901916643175236\n",
            "Train-Test: 0.28394340773665666\n",
            "112\n",
            "Mean value of R2 of training set 0.6396501007830365\n",
            "Mean value of R2 of test set 0.3647228925593447\n",
            "Standard deviation of R2 of test set 0.13943384601488493\n",
            "Train-Test: 0.2749272082236918\n",
            "113\n",
            "Mean value of R2 of training set 0.6385765858061319\n",
            "Mean value of R2 of test set 0.3705437106007565\n",
            "Standard deviation of R2 of test set 0.13119537857546631\n",
            "Train-Test: 0.26803287520537533\n",
            "114\n",
            "Mean value of R2 of training set 0.6418270680699054\n",
            "Mean value of R2 of test set 0.35699702653419896\n",
            "Standard deviation of R2 of test set 0.13492069761812037\n",
            "Train-Test: 0.28483004153570646\n",
            "115\n",
            "Mean value of R2 of training set 0.6404920636854011\n",
            "Mean value of R2 of test set 0.3662087477448221\n",
            "Standard deviation of R2 of test set 0.14400293971115877\n",
            "Train-Test: 0.27428331594057903\n",
            "116\n",
            "Mean value of R2 of training set 0.6289967005574953\n",
            "Mean value of R2 of test set 0.353310943895967\n",
            "Standard deviation of R2 of test set 0.140691845900584\n",
            "Train-Test: 0.27568575666152834\n",
            "117\n",
            "Mean value of R2 of training set 0.6301575575460033\n",
            "Mean value of R2 of test set 0.36515147666931563\n",
            "Standard deviation of R2 of test set 0.13926822106824222\n",
            "Train-Test: 0.2650060808766877\n",
            "118\n",
            "Mean value of R2 of training set 0.6409939877024741\n",
            "Mean value of R2 of test set 0.3604461879485459\n",
            "Standard deviation of R2 of test set 0.14294559313581304\n",
            "Train-Test: 0.2805477997539282\n",
            "119\n",
            "Mean value of R2 of training set 0.646058151207376\n",
            "Mean value of R2 of test set 0.3642914269656679\n",
            "Standard deviation of R2 of test set 0.13424422931944796\n",
            "Train-Test: 0.28176672424170807\n",
            "120\n",
            "Mean value of R2 of training set 0.6423687224045527\n",
            "Mean value of R2 of test set 0.34838971601997776\n",
            "Standard deviation of R2 of test set 0.14828939988980364\n",
            "Train-Test: 0.2939790063845749\n",
            "121\n",
            "Mean value of R2 of training set 0.6399140914785716\n",
            "Mean value of R2 of test set 0.3592102302239482\n",
            "Standard deviation of R2 of test set 0.14064329923301883\n",
            "Train-Test: 0.2807038612546234\n",
            "122\n",
            "Mean value of R2 of training set 0.635890568690436\n",
            "Mean value of R2 of test set 0.3696419863053471\n",
            "Standard deviation of R2 of test set 0.14807873211045633\n",
            "Train-Test: 0.2662485823850889\n",
            "123\n",
            "Mean value of R2 of training set 0.6346782451929317\n",
            "Mean value of R2 of test set 0.3431978739801695\n",
            "Standard deviation of R2 of test set 0.14595066997108078\n",
            "Train-Test: 0.2914803712127622\n",
            "124\n",
            "Mean value of R2 of training set 0.6350554102793321\n",
            "Mean value of R2 of test set 0.3509080866051455\n",
            "Standard deviation of R2 of test set 0.1411265049609161\n",
            "Train-Test: 0.2841473236741866\n",
            "125\n",
            "Mean value of R2 of training set 0.6420874654481652\n",
            "Mean value of R2 of test set 0.36549475451603824\n",
            "Standard deviation of R2 of test set 0.13748723853314487\n",
            "Train-Test: 0.27659271093212695\n",
            "126\n",
            "Mean value of R2 of training set 0.6346301561713348\n",
            "Mean value of R2 of test set 0.3423126849587538\n",
            "Standard deviation of R2 of test set 0.14426559256407562\n",
            "Train-Test: 0.292317471212581\n",
            "127\n",
            "Mean value of R2 of training set 0.6494388067748355\n",
            "Mean value of R2 of test set 0.3768644956610608\n",
            "Standard deviation of R2 of test set 0.14762222685770524\n",
            "Train-Test: 0.27257431111377467\n",
            "128\n",
            "Mean value of R2 of training set 0.6371999971814641\n",
            "Mean value of R2 of test set 0.3481956137607436\n",
            "Standard deviation of R2 of test set 0.14682164392586686\n",
            "Train-Test: 0.28900438342072055\n",
            "129\n",
            "Mean value of R2 of training set 0.6464825740266942\n",
            "Mean value of R2 of test set 0.36635083886692693\n",
            "Standard deviation of R2 of test set 0.14644118370418205\n",
            "Train-Test: 0.28013173515976725\n",
            "130\n",
            "Mean value of R2 of training set 0.6408974902073663\n",
            "Mean value of R2 of test set 0.3683100181714162\n",
            "Standard deviation of R2 of test set 0.1355904857683573\n",
            "Train-Test: 0.27258747203595013\n",
            "131\n",
            "Mean value of R2 of training set 0.6408759896616608\n",
            "Mean value of R2 of test set 0.35985554446582685\n",
            "Standard deviation of R2 of test set 0.1414531621247636\n",
            "Train-Test: 0.28102044519583397\n",
            "132\n",
            "Mean value of R2 of training set 0.6432565717216534\n",
            "Mean value of R2 of test set 0.35915415485313007\n",
            "Standard deviation of R2 of test set 0.1516822358285623\n",
            "Train-Test: 0.28410241686852333\n",
            "133\n",
            "Mean value of R2 of training set 0.6349110864003543\n",
            "Mean value of R2 of test set 0.3516810182642691\n",
            "Standard deviation of R2 of test set 0.13367048553102792\n",
            "Train-Test: 0.2832300681360852\n",
            "134\n",
            "Mean value of R2 of training set 0.6380589587132895\n",
            "Mean value of R2 of test set 0.3639103669072547\n",
            "Standard deviation of R2 of test set 0.14403943303876218\n",
            "Train-Test: 0.27414859180603485\n",
            "135\n",
            "Mean value of R2 of training set 0.6323761693082974\n",
            "Mean value of R2 of test set 0.35696690410451565\n",
            "Standard deviation of R2 of test set 0.13548596333767027\n",
            "Train-Test: 0.2754092652037818\n",
            "136\n",
            "Mean value of R2 of training set 0.6370023509244668\n",
            "Mean value of R2 of test set 0.36048166726010733\n",
            "Standard deviation of R2 of test set 0.1387476029139923\n",
            "Train-Test: 0.27652068366435945\n",
            "137\n",
            "Mean value of R2 of training set 0.6347186630992394\n",
            "Mean value of R2 of test set 0.35370953109442943\n",
            "Standard deviation of R2 of test set 0.14184275944106478\n",
            "Train-Test: 0.28100913200481\n",
            "138\n",
            "Mean value of R2 of training set 0.6439777286256763\n",
            "Mean value of R2 of test set 0.35878343707257443\n",
            "Standard deviation of R2 of test set 0.14798352016248417\n",
            "Train-Test: 0.28519429155310183\n",
            "139\n",
            "Mean value of R2 of training set 0.6275587286805442\n",
            "Mean value of R2 of test set 0.3575771142617105\n",
            "Standard deviation of R2 of test set 0.13471143843170091\n",
            "Train-Test: 0.26998161441883367\n",
            "140\n",
            "Mean value of R2 of training set 0.6450409842506873\n",
            "Mean value of R2 of test set 0.35456497213247284\n",
            "Standard deviation of R2 of test set 0.15160405868361665\n",
            "Train-Test: 0.2904760121182145\n",
            "141\n",
            "Mean value of R2 of training set 0.6367787458506942\n",
            "Mean value of R2 of test set 0.3630944191381318\n",
            "Standard deviation of R2 of test set 0.1487568896181726\n",
            "Train-Test: 0.2736843267125624\n",
            "142\n",
            "Mean value of R2 of training set 0.6442176021160831\n",
            "Mean value of R2 of test set 0.35160802282178366\n",
            "Standard deviation of R2 of test set 0.13965426281178187\n",
            "Train-Test: 0.2926095792942995\n",
            "143\n",
            "Mean value of R2 of training set 0.6478037662678778\n",
            "Mean value of R2 of test set 0.3640841570041901\n",
            "Standard deviation of R2 of test set 0.14659243615440795\n",
            "Train-Test: 0.2837196092636877\n",
            "144\n",
            "Mean value of R2 of training set 0.6392652165346469\n",
            "Mean value of R2 of test set 0.35174280158072585\n",
            "Standard deviation of R2 of test set 0.14317710200159356\n",
            "Train-Test: 0.287522414953921\n",
            "145\n",
            "Mean value of R2 of training set 0.6335972684322309\n",
            "Mean value of R2 of test set 0.3652378994579557\n",
            "Standard deviation of R2 of test set 0.14139387587829993\n",
            "Train-Test: 0.26835936897427515\n",
            "146\n",
            "Mean value of R2 of training set 0.6355024117194863\n",
            "Mean value of R2 of test set 0.3430057008107897\n",
            "Standard deviation of R2 of test set 0.13411817641004278\n",
            "Train-Test: 0.2924967109086966\n",
            "147\n",
            "Mean value of R2 of training set 0.6394140905483553\n",
            "Mean value of R2 of test set 0.3573012940120335\n",
            "Standard deviation of R2 of test set 0.1387909351998393\n",
            "Train-Test: 0.2821127965363218\n",
            "148\n",
            "Mean value of R2 of training set 0.6388686478404173\n",
            "Mean value of R2 of test set 0.3496920086356322\n",
            "Standard deviation of R2 of test set 0.14821559205935994\n",
            "Train-Test: 0.2891766392047851\n",
            "149\n",
            "Mean value of R2 of training set 0.6409725334979671\n",
            "Mean value of R2 of test set 0.36066174588996786\n",
            "Standard deviation of R2 of test set 0.13772433784914714\n",
            "Train-Test: 0.28031078760799927\n",
            "150\n",
            "Mean value of R2 of training set 0.6350293942481412\n",
            "Mean value of R2 of test set 0.35638355197030014\n",
            "Standard deviation of R2 of test set 0.13417861726907682\n",
            "Train-Test: 0.27864584227784106\n",
            "151\n",
            "Mean value of R2 of training set 0.6482515726640327\n",
            "Mean value of R2 of test set 0.3650449206669443\n",
            "Standard deviation of R2 of test set 0.13825424681761872\n",
            "Train-Test: 0.2832066519970884\n",
            "152\n",
            "Mean value of R2 of training set 0.6333750401398436\n",
            "Mean value of R2 of test set 0.3549713499991208\n",
            "Standard deviation of R2 of test set 0.15557444617543695\n",
            "Train-Test: 0.2784036901407228\n",
            "153\n",
            "Mean value of R2 of training set 0.6425590270843032\n",
            "Mean value of R2 of test set 0.3599679173680632\n",
            "Standard deviation of R2 of test set 0.14154557521551578\n",
            "Train-Test: 0.28259110971624\n",
            "154\n",
            "Mean value of R2 of training set 0.6479558559891143\n",
            "Mean value of R2 of test set 0.3665529595117043\n",
            "Standard deviation of R2 of test set 0.14929343991378724\n",
            "Train-Test: 0.28140289647741\n",
            "155\n",
            "Mean value of R2 of training set 0.6377540041016644\n",
            "Mean value of R2 of test set 0.3595608328785325\n",
            "Standard deviation of R2 of test set 0.1370264007288647\n",
            "Train-Test: 0.27819317122313186\n",
            "156\n",
            "Mean value of R2 of training set 0.6447467661893559\n",
            "Mean value of R2 of test set 0.3543197851466393\n",
            "Standard deviation of R2 of test set 0.14836836595814995\n",
            "Train-Test: 0.2904269810427166\n",
            "157\n",
            "Mean value of R2 of training set 0.6359291986854805\n",
            "Mean value of R2 of test set 0.3618704793130395\n",
            "Standard deviation of R2 of test set 0.14144617966320955\n",
            "Train-Test: 0.274058719372441\n",
            "158\n",
            "Mean value of R2 of training set 0.6267688012470092\n",
            "Mean value of R2 of test set 0.3690375684235172\n",
            "Standard deviation of R2 of test set 0.13423338099425375\n",
            "Train-Test: 0.257731232823492\n",
            "159\n",
            "Mean value of R2 of training set 0.6373704983022089\n",
            "Mean value of R2 of test set 0.3520245241163176\n",
            "Standard deviation of R2 of test set 0.14407900021713305\n",
            "Train-Test: 0.2853459741858913\n",
            "160\n",
            "Mean value of R2 of training set 0.6339875021980428\n",
            "Mean value of R2 of test set 0.36811033343745075\n",
            "Standard deviation of R2 of test set 0.1392377108151691\n",
            "Train-Test: 0.26587716876059203\n",
            "161\n",
            "Mean value of R2 of training set 0.6413593229990543\n",
            "Mean value of R2 of test set 0.360275086459154\n",
            "Standard deviation of R2 of test set 0.13862629043511682\n",
            "Train-Test: 0.2810842365399003\n",
            "162\n",
            "Mean value of R2 of training set 0.6462877317050658\n",
            "Mean value of R2 of test set 0.3506645630716584\n",
            "Standard deviation of R2 of test set 0.14608998160308195\n",
            "Train-Test: 0.29562316863340743\n",
            "163\n",
            "Mean value of R2 of training set 0.6339939154688577\n",
            "Mean value of R2 of test set 0.35456816128312724\n",
            "Standard deviation of R2 of test set 0.14085065423061366\n",
            "Train-Test: 0.2794257541857305\n",
            "164\n",
            "Mean value of R2 of training set 0.64235394388099\n",
            "Mean value of R2 of test set 0.36409439813063327\n",
            "Standard deviation of R2 of test set 0.1480850454067519\n",
            "Train-Test: 0.2782595457503567\n",
            "165\n",
            "Mean value of R2 of training set 0.6459495284089107\n",
            "Mean value of R2 of test set 0.36581705401830583\n",
            "Standard deviation of R2 of test set 0.145000004843994\n",
            "Train-Test: 0.2801324743906049\n",
            "166\n",
            "Mean value of R2 of training set 0.6406290197411711\n",
            "Mean value of R2 of test set 0.3735927476158507\n",
            "Standard deviation of R2 of test set 0.13915001053531498\n",
            "Train-Test: 0.26703627212532044\n",
            "167\n",
            "Mean value of R2 of training set 0.6317358895293692\n",
            "Mean value of R2 of test set 0.37461083136315304\n",
            "Standard deviation of R2 of test set 0.13832992973739688\n",
            "Train-Test: 0.25712505816621617\n",
            "168\n",
            "Mean value of R2 of training set 0.647692206292462\n",
            "Mean value of R2 of test set 0.3617031611578701\n",
            "Standard deviation of R2 of test set 0.13628618937312414\n",
            "Train-Test: 0.28598904513459195\n",
            "169\n",
            "Mean value of R2 of training set 0.643920156733692\n",
            "Mean value of R2 of test set 0.3622926779664045\n",
            "Standard deviation of R2 of test set 0.14521532865517975\n",
            "Train-Test: 0.28162747876728744\n",
            "170\n",
            "Mean value of R2 of training set 0.6392093055705561\n",
            "Mean value of R2 of test set 0.3612670308418444\n",
            "Standard deviation of R2 of test set 0.1474524306958329\n",
            "Train-Test: 0.2779422747287117\n",
            "171\n",
            "Mean value of R2 of training set 0.6367353925056911\n",
            "Mean value of R2 of test set 0.35413836357506867\n",
            "Standard deviation of R2 of test set 0.14009733554802473\n",
            "Train-Test: 0.28259702893062244\n",
            "172\n",
            "Mean value of R2 of training set 0.645264213733618\n",
            "Mean value of R2 of test set 0.35169086095180196\n",
            "Standard deviation of R2 of test set 0.1394893840078822\n",
            "Train-Test: 0.293573352781816\n",
            "173\n",
            "Mean value of R2 of training set 0.6333384346207553\n",
            "Mean value of R2 of test set 0.3652219520486225\n",
            "Standard deviation of R2 of test set 0.14637713913851597\n",
            "Train-Test: 0.26811648257213283\n",
            "174\n",
            "Mean value of R2 of training set 0.642652169016721\n",
            "Mean value of R2 of test set 0.3503867548568978\n",
            "Standard deviation of R2 of test set 0.14277116738743237\n",
            "Train-Test: 0.29226541415982316\n",
            "175\n",
            "Mean value of R2 of training set 0.6415418978208826\n",
            "Mean value of R2 of test set 0.37320682744075756\n",
            "Standard deviation of R2 of test set 0.13587320517236154\n",
            "Train-Test: 0.268335070380125\n",
            "176\n",
            "Mean value of R2 of training set 0.6324811604383546\n",
            "Mean value of R2 of test set 0.3585193585339335\n",
            "Standard deviation of R2 of test set 0.1380473219036534\n",
            "Train-Test: 0.27396180190442104\n",
            "177\n",
            "Mean value of R2 of training set 0.6404128652705787\n",
            "Mean value of R2 of test set 0.37678112176642764\n",
            "Standard deviation of R2 of test set 0.13497236625094436\n",
            "Train-Test: 0.2636317435041511\n",
            "178\n",
            "Mean value of R2 of training set 0.6407813029607771\n",
            "Mean value of R2 of test set 0.35508494373809796\n",
            "Standard deviation of R2 of test set 0.13915679124337116\n",
            "Train-Test: 0.2856963592226791\n",
            "179\n",
            "Mean value of R2 of training set 0.6329474351835066\n",
            "Mean value of R2 of test set 0.36627792122071945\n",
            "Standard deviation of R2 of test set 0.1436726457734053\n",
            "Train-Test: 0.26666951396278715\n",
            "180\n",
            "Mean value of R2 of training set 0.6420418412518545\n",
            "Mean value of R2 of test set 0.358056214075948\n",
            "Standard deviation of R2 of test set 0.14769179882200223\n",
            "Train-Test: 0.2839856271759065\n",
            "181\n",
            "Mean value of R2 of training set 0.6409008384951513\n",
            "Mean value of R2 of test set 0.34785801354017143\n",
            "Standard deviation of R2 of test set 0.14030174414671986\n",
            "Train-Test: 0.2930428249549799\n",
            "182\n",
            "Mean value of R2 of training set 0.6364730400335947\n",
            "Mean value of R2 of test set 0.36192830071462867\n",
            "Standard deviation of R2 of test set 0.14033609783674145\n",
            "Train-Test: 0.27454473931896606\n",
            "183\n",
            "Mean value of R2 of training set 0.6315956559224568\n",
            "Mean value of R2 of test set 0.36717257665580355\n",
            "Standard deviation of R2 of test set 0.13975988478179333\n",
            "Train-Test: 0.26442307926665326\n",
            "184\n",
            "Mean value of R2 of training set 0.6418118890893819\n",
            "Mean value of R2 of test set 0.3621465961694737\n",
            "Standard deviation of R2 of test set 0.1386122724866057\n",
            "Train-Test: 0.2796652929199082\n",
            "185\n",
            "Mean value of R2 of training set 0.6384460365122574\n",
            "Mean value of R2 of test set 0.35110473723642877\n",
            "Standard deviation of R2 of test set 0.1510139410721998\n",
            "Train-Test: 0.28734129927582863\n",
            "186\n",
            "Mean value of R2 of training set 0.6360054931174721\n",
            "Mean value of R2 of test set 0.3617645401023911\n",
            "Standard deviation of R2 of test set 0.1364518146183932\n",
            "Train-Test: 0.274240953015081\n",
            "187\n",
            "Mean value of R2 of training set 0.6472237240322383\n",
            "Mean value of R2 of test set 0.3603956717538594\n",
            "Standard deviation of R2 of test set 0.14270986845122022\n",
            "Train-Test: 0.2868280522783789\n",
            "188\n",
            "Mean value of R2 of training set 0.6481512637624224\n",
            "Mean value of R2 of test set 0.36273914036056054\n",
            "Standard deviation of R2 of test set 0.14140433177374875\n",
            "Train-Test: 0.28541212340186184\n",
            "189\n",
            "Mean value of R2 of training set 0.6331117126579666\n",
            "Mean value of R2 of test set 0.36194027202495216\n",
            "Standard deviation of R2 of test set 0.13793705633230519\n",
            "Train-Test: 0.27117144063301446\n",
            "190\n",
            "Mean value of R2 of training set 0.6329041938454455\n",
            "Mean value of R2 of test set 0.3648730885883103\n",
            "Standard deviation of R2 of test set 0.1404397976451425\n",
            "Train-Test: 0.2680311052571352\n",
            "191\n",
            "Mean value of R2 of training set 0.6416323275290234\n",
            "Mean value of R2 of test set 0.3617296572027434\n",
            "Standard deviation of R2 of test set 0.1355690495697607\n",
            "Train-Test: 0.27990267032628\n",
            "192\n",
            "Mean value of R2 of training set 0.6374994205780561\n",
            "Mean value of R2 of test set 0.37937914416021107\n",
            "Standard deviation of R2 of test set 0.13879879734473488\n",
            "Train-Test: 0.258120276417845\n",
            "193\n",
            "Mean value of R2 of training set 0.6334583096173181\n",
            "Mean value of R2 of test set 0.3470710982182497\n",
            "Standard deviation of R2 of test set 0.14914621182856178\n",
            "Train-Test: 0.28638721139906836\n",
            "194\n",
            "Mean value of R2 of training set 0.6314468262370493\n",
            "Mean value of R2 of test set 0.35473933199037694\n",
            "Standard deviation of R2 of test set 0.13655528521801577\n",
            "Train-Test: 0.27670749424667235\n",
            "195\n",
            "Mean value of R2 of training set 0.6438129882371045\n",
            "Mean value of R2 of test set 0.36122712439066573\n",
            "Standard deviation of R2 of test set 0.14563442875345148\n",
            "Train-Test: 0.2825858638464388\n",
            "196\n",
            "Mean value of R2 of training set 0.6472481864624829\n",
            "Mean value of R2 of test set 0.37655828940867464\n",
            "Standard deviation of R2 of test set 0.14063957081707346\n",
            "Train-Test: 0.2706898970538083\n",
            "197\n",
            "Mean value of R2 of training set 0.6411461354120549\n",
            "Mean value of R2 of test set 0.36079710764560824\n",
            "Standard deviation of R2 of test set 0.13871437905591755\n",
            "Train-Test: 0.28034902776644666\n",
            "198\n",
            "Mean value of R2 of training set 0.6410666119542703\n",
            "Mean value of R2 of test set 0.3582449770252556\n",
            "Standard deviation of R2 of test set 0.14012071956416913\n",
            "Train-Test: 0.2828216349290147\n",
            "199\n",
            "Mean value of R2 of training set 0.6480529835355918\n",
            "Mean value of R2 of test set 0.36173536757533337\n",
            "Standard deviation of R2 of test set 0.1426801645553673\n",
            "Train-Test: 0.28631761596025845\n",
            "200\n",
            "Mean value of R2 of training set 0.6306449725852885\n",
            "Mean value of R2 of test set 0.3648411548415568\n",
            "Standard deviation of R2 of test set 0.14358475722254416\n",
            "Train-Test: 0.2658038177437317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u9GRIXxn9eV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5efde408-5090-4353-b090-d2b2507ee8f4"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TODO Calculate the r2 score between 'y_true' and 'y_predict'\n",
        "from math import sqrt\n",
        "from sklearn import metrics\n",
        "\n",
        "group2 = Original_Features.loc[:,'Group']\n",
        "\n",
        "# TODO: Shuffle and split the data into training and testing subsets\n",
        "Features, X_valid, Oil_HHV, y_valid = train_test_split(Original_Features, Original_Oil_HHV, test_size = 0.1, stratify=group2, random_state=62)\n",
        "\n",
        "X_valid_new=X_valid.drop('Group', axis=1)\n",
        "\n",
        "Features_new=Features.drop('Group', axis=1)\n",
        "\n",
        "cnt = 1\n",
        "\n",
        "MAE_train_all=[]\n",
        "MAE_test_all=[]\n",
        "y_train_rmse_all=[]\n",
        "y_test_rmse_all=[]\n",
        "r2_train_all=[]\n",
        "r2_test_all=[]\n",
        "MRE_train_all=[]\n",
        "MRE_test_all=[]\n",
        "y_test_list=[]\n",
        "y_pred_list=[]\n",
        "\n",
        "for i in range(5000,6000,10):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(Features_new, Oil_HHV, shuffle=True, test_size = 0.2, random_state=i)\n",
        "\n",
        "  #other_params = {'eta': 0.01, 'n_estimators': 50, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 4,\n",
        "  #              'colsample_bytree': 1, 'colsample_bylevel': 1, 'subsample': 0.6002, 'reg_lambda': 0.9693, 'reg_alpha': 0,\n",
        "  #              'seed': 33}\n",
        "  \n",
        "  #other_params = {'eta': 0.01, 'n_estimators': 60, 'gamma': 0.27, 'max_depth': 2, 'min_child_weight': 1,\n",
        "  #              'colsample_bytree': 0.3, 'colsample_bylevel': 1, 'subsample': 0.9438, 'reg_lambda': 0.0519, 'reg_alpha': 0,\n",
        "  #              'seed': 192}\n",
        "\n",
        "  #model = XGBRegressor(**other_params,silent = True)\n",
        "\n",
        "  model = XGBRegressor(silent = True)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "    \n",
        "  y_train_predict = model.predict(X_train)\n",
        "  y_test_predict = model.predict(X_test)\n",
        "\n",
        "  MAE_train = metrics.mean_absolute_error(y_train, y_train_predict)\n",
        "  MAE_test = metrics.mean_absolute_error(y_test, y_test_predict)\n",
        "    \n",
        "  y_train_rmse = sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
        "  y_test_rmse = sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
        "    \n",
        "  r2_train = metrics.r2_score(y_train, y_train_predict)\n",
        "  r2_test = metrics.r2_score(y_test, y_test_predict)\n",
        "\n",
        "  MRE_train = performance_metric(y_train, y_train_predict)\n",
        "  MRE_test = performance_metric(y_test, y_test_predict)\n",
        "\n",
        "  cnt += 1\n",
        "  MAE_train_all.append(MAE_train)\n",
        "  MAE_test_all.append(MAE_test)\n",
        "  y_train_rmse_all.append(y_train_rmse)\n",
        "  y_test_rmse_all.append(y_test_rmse)\n",
        "  r2_train_all.append(r2_train)\n",
        "  r2_test_all.append(r2_test)\n",
        "  MRE_train_all.append(MRE_train)\n",
        "  MRE_test_all.append(MRE_test)\n",
        "\n",
        "  # For drawing plot\n",
        "  y_test_list.append(y_test.values)\n",
        "  y_pred_list.append(y_test_predict)  \n",
        "\n",
        "y_test_all=np.concatenate(y_test_list, axis=0)\n",
        "y_pred_all=np.concatenate(y_pred_list, axis=0)\n",
        "\n",
        "print(\"Mean value of MAE of training set\", np.mean(MAE_train_all))\n",
        "print(\"Standard deviation of MAE of training set\", np.std(MAE_train_all))\n",
        "print(\"Mean value of MAE of test set\", np.mean(MAE_test_all))\n",
        "print(\"Standard deviation of MAE of test set\", np.std(MAE_test_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of RMSE of training set\", np.mean(y_train_rmse_all))\n",
        "print(\"Standard deviation of RMSE of training set\", np.std(y_train_rmse_all))\n",
        "print(\"Mean value of RMSE of test set\", np.mean(y_test_rmse_all))\n",
        "print(\"Standard deviation of RMSE of test set\", np.std(y_test_rmse_all))\n",
        "print(\"\")\n",
        "print(\"Mean value of R2 of training set\", np.mean(r2_train_all))\n",
        "print(\"Standard deviation of R2 of training set\", np.std(r2_train_all))\n",
        "print(\"Mean value of R2 of test set\", np.mean(r2_test_all))\n",
        "print(\"Standard deviation of R2 of test set\", np.std(r2_test_all))\n",
        "#print(\"Value of R2 of test set\", r2_test_all)\n",
        "print(\"\")\n",
        "print(\"Mean value of MRE of training set\", np.mean(MRE_train_all))\n",
        "print(\"Standard deviation of MRE of training set\", np.std(MRE_train_all))\n",
        "print(\"Mean value of MRE of test set\", np.mean(MRE_test_all))\n",
        "print(\"Standard deviation of MRE of test set\", np.std(MRE_test_all))\n",
        "\n",
        "print(\"\")\n",
        "# Predict validation set\n",
        "model.fit(Features_new, Oil_HHV)\n",
        "\n",
        "y_valid_predict = model.predict(X_valid_new)\n",
        "\n",
        "MAE_valid = metrics.mean_absolute_error(y_valid, y_valid_predict)\n",
        "y_valid_rmse = sqrt(metrics.mean_squared_error(y_valid, y_valid_predict))\n",
        "r2_valid = metrics.r2_score(y_valid, y_valid_predict)\n",
        "MRE_valid = performance_metric(y_valid, y_valid_predict)\n",
        "\n",
        "print(\"MAE of valid set:\", MAE_valid)\n",
        "print(\"RMSE of valid set:\", y_valid_rmse)\n",
        "print(\"R2 score of valid set\", r2_valid)\n",
        "print(\"MRE of valid set:\", MRE_valid)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean value of MAE of training set 1.2749806572774443\n",
            "Standard deviation of MAE of training set 0.05642658004101939\n",
            "Mean value of MAE of test set 2.3295810256194414\n",
            "Standard deviation of MAE of test set 0.27708715237472253\n",
            "\n",
            "Mean value of RMSE of training set 1.7147676671772598\n",
            "Standard deviation of RMSE of training set 0.08088164073261468\n",
            "Mean value of RMSE of test set 3.2671033180036595\n",
            "Standard deviation of RMSE of test set 0.469614817511136\n",
            "\n",
            "Mean value of R2 of training set 0.8230302554392899\n",
            "Standard deviation of R2 of training set 0.01594912058068607\n",
            "Mean value of R2 of test set 0.33682558020646686\n",
            "Standard deviation of R2 of test set 0.17665355497464583\n",
            "\n",
            "Mean value of MRE of training set 0.03780475807848835\n",
            "Standard deviation of MRE of training set 0.0016749187425234265\n",
            "Mean value of MRE of test set 0.0690762992216633\n",
            "Standard deviation of MRE of test set 0.008396953721059584\n",
            "\n",
            "MAE of valid set: 2.628640412197113\n",
            "RMSE of valid set: 3.213031321846453\n",
            "R2 score of valid set 0.5565559149296786\n",
            "MRE of valid set: 0.07737081109289233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxNoznXg7WeT"
      },
      "source": [
        "Parity={'Predict Data':y_pred_all,'Test Data':y_test_all}\n",
        "df = pd.DataFrame(Parity, columns= ['Predict Data', 'Test Data'])\n",
        "df.to_csv (r'/content/export_dataframe_XGBoost_opt.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "GuplwoaQoXyK",
        "outputId": "d616cb4b-1dbe-4b8b-9ae0-dd2415a70225"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_test_all, y_pred_all, 'bo')\n",
        "py.ylim(20, 43)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8RqjjeQnoRtA",
        "outputId": "fc1b72c3-a45a-41d9-cc82-b3e9bd2db49a"
      },
      "source": [
        "from xgboost import plot_importance\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "f4qdfxcnvGxq",
        "outputId": "a276ac98-c099-409a-decf-ff000b5cb682"
      },
      "source": [
        "import matplotlib.pyplot as py\n",
        "py.plot(y_valid, y_valid_predict, 'bo')\n",
        "py.ylim(20, 43)\n",
        "py.xlabel('y_true')\n",
        "py.ylabel('y_pred')\n",
        "py.title('y_pred vs. y_true')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'y_pred vs. y_true')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}